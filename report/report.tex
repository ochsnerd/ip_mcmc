% Created 2020-06-15 Mo 14:23
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage{minted}
\usepackage{physics}
\usepackage{dsfont}
\newcommand{\C}{{\mathcal{C}}}
\newcommand{\I}{{\mathcal{I}}}
\newcommand{\R}{{\mathbb{R}}}
\newcommand{\NN}{{\mathbb{N}}}
\newcommand{\G}[1]{{\mathcal{G} \left( #1 \right)}}
\newcommand{\E}[1]{{\mathop{\mathbb{E}}\left[ #1 \right]}}
\newcommand{\N}[2]{\mathcal{N}\left(#1,#2\right)}
\author{David Ochsner}
\date{\today}
\title{Markov Chain Monte Carlo for Inverse Problems}
\hypersetup{
 pdfauthor={David Ochsner},
 pdftitle={Markov Chain Monte Carlo for Inverse Problems},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 26.3 (Org mode 9.1.9)}, 
 pdflang={English}}
\begin{document}

\maketitle
\tableofcontents


\section{Theory}
\label{sec:org6ea92e7}
\subsection{Papers}
\label{sec:org66774de}
\subsubsection{Stuart et al: Inverse Problems: A Bayesian Perspective \cite{stuart_inverse_2010}}
\label{sec:org37a87f1}
Theoretical Background
\paragraph{Notation}
\label{sec:org74a2889}
Central equation:
$$y = \G{u} + \eta$$
with:
\begin{itemize}
\item \(y \in \R^q\): data
\item \(u \in \R^n\): IC ("input to mathematical model")
\item \(\G{\cdot} :\R^n \to \R^q\): observation operator
\item \(\eta\): mean zero RV, observational noise (a.s. \(\eta \sim \N{0}{\C}\))
\end{itemize}
\subsubsection{Cotter et al: MCMC for functions \cite{cotter_mcmc_2013}}
\label{sec:org91a822c}
Implementation, MCMC in infinite dimensions
\subsubsection{Schneider et al: Earth System Modeling 2.0  \cite{schneider_earth_2017}}
\label{sec:orgf083f94}
Example for MCMC on ODE
\subsection{Small results}
\label{sec:org4f274ce}
\subsubsection{Gaussian in infinite dimensions}
\label{sec:org07d1208}
This section is quite a mess, maybe you could suggest a not-too-technical introduction
to infinite dimensional Gaussian measures?

Wiki: Definition of Gaussian measure uses Lesbesgue measure.
However, the Lesbesgue-Measure is not defined in an infinite-dimensional space (\href{https://en.wikipedia.org/wiki/Infinite-dimensional\_Lebesgue\_measure}{wiki}).

Can still define a measure to be Gaussian if we demand all push-forward measures via a
linear functional onto \(\R\) to be a Gaussian. (What about the star (E\(^{\text{*}}\), L\(_{\text{*}}\))
in the wiki-article? Are they dual-spaces?) (What would be an example of that? An example
for a linear functional on an inf-dims space given on wikipedia is integration.
What do we integrate? How does this lead to a Gaussian?)

How does this fit with the description in \cite{cotter_mcmc_2013}? -> Karhunenen-Loéve

What would be an example of a covariance operator in infinite dimensions?
The Laplace-Operator operates on functions, the eigenfunctions would be \(sin\), \(cos\) (I think?
This might not actually be so easy, see \href{https://en.wikipedia.org/wiki/Dirichlet\_eigenvalue}{Dirichlet Eigenvalues}). Are the eigenvalues
square-summable?

Anyway, when a inf-dim Gaussian is given as a KL-Expansion, an  example of a linear functional
given as \(f(u) = \langle \phi_i, u \rangle\) for \(\phi_i\) an eigenfunction of \(\C\), then I can see
the push-forward definition of inf-dim Gaussians satisfied. ( \(\C\) spd, so \(\phi_i\) s are
orthogonal, so we just end up with one of the KH-"components" which is given to be \(\N{0}{1})\).

The problem is not actually in \(\exp(-1/2x^T\C^{-1}x)\). What about \(\exp(-1/2\norm{\C^{-1/2}x})\)?

What about the terminology in \cite{cotter_mcmc_2013}? Absolutely continuous w.r.t a measure for
example?

How is the square root of an operator defined? For matrices, there seems to be a freedom in
choosing whether \(A = BB\) or \(A = BB^T\) for \(B = A^{1/2}\). The latter definition seems to
be more useful when working with Cholesky factorizations (cf. \url{https://math.stackexchange.com/questions/2767873/why-is-the-square-root-of-cholesky-decomposition-equal-to-the-lower-triangular-m}),
but for example in the wiki-article about the matrix (operator) square root (\url{https://en.wikipedia.org/wiki/Square\_root\_of\_a\_matrix}):
"The Cholesky factorization provides another particular example of square root, which should not be confused with the unique non-negative square root."

\subsubsection{Bayes' Formula \& Radon-Nikodym Derivative}
\label{sec:orgf85da65}
Bayes' Formula is stated using the Radon-Nikodym Derivative in both \cite{cotter_mcmc_2013} and \cite{stuart_inverse_2010}:
$$\dv{\mu}{\mu_0} \propto \text{L}(u),$$
where \(\text{L}(u)\) is the likelihood.

Write the measures as \(\dd \mu = \rho(u)\dd u\) and \(\dd \mu_0 = \rho_0(u)\dd u\) with respect
to the standard Lesbesgue measure. Then we have
$$
    \int f(u) \rho(u) \dd u =
    \int f(u) \dd \mu(u) =
    \int f(u) \dv{\mu(u)}{\mu_0(u)} \dd \mu_0 =
    \int f(u) \dv{\mu(u)}{\mu_0(u)} \rho_0(u) \dd u,
    $$
provided that \(\dd \mu\), \(\dd \mu_0\) and \(f\) are nice enough (which they are since we're working
with Gaussians). This holds for all test functions \(f\), so it must hold pointwise:
$$ \dv{\mu(u)}{\mu_0(u)} = \frac{\rho(u)}{\rho_o(u)}.$$

Using this we recover the more familiar formulation of Bayes' formula:
$$\frac{\rho(u)}{\rho_o(u)} \propto \text{L}(u).$$

\subsubsection{Acceptance Probability for Metropolis-Hastings}
\label{sec:org42d142b}
A Markov process with transition probabilities \(t(y|x)\) has a stationary distribution \(\pi(x)\).
\begin{itemize}
\item The \uline{existence} of \(\pi(x)\) follows from \emph{detailed balance}:
$$\pi(x)t(y|x) = \pi(y)t(x|y).$$
Detailed balance is sufficient but not necessary for the existence of a stationary distribution.
\item \uline{Uniqueness} of \(\pi(x)\) follows from the Ergodicity of the Markov process. For a Markov
processto be Ergodic it has to:
\begin{itemize}
\item not return to the same state in a fixed interval
\item reach every state from every other state in finite time
\end{itemize}
\end{itemize}

The Metropolis-Hastings algorithm constructs transition probabilities \(t(y|x)\) such that the
two conditions above are satisfied and that \(\pi(x) = P(x)\), where \(P(x)\) is the distribution
we want to sample from.

Rewrite detailed balance as
$$\frac{t(y|x)}{t(x|y)} = \frac{P(y)}{P(x)}.$$
Split up the transition probability into proposal \(g(y|x)\) and acceptance \(a(y,x)\). Then detailed
balance requires
$$\frac{a(y,x)}{a(x,y)} = \frac{P(y)g(x|y)}{P(x)g(y|x)}.$$
Choose
$$a(y,x) = \min\left\{1, \frac{P(y)g(x|y)}{P(x)g(y|x)}\right\}$$
to ensure that detailed balance is always satisfied. Choose \(g(y|x)\) such that ergodicity
is fulfilled.

If the proposal is symmetric (\(g(y|x) = g(x|y)\)), then the acceptance takes the simpler form
\begin{equation}
\label{eqn:acceptance_simple}
a(y,x) = \min\left\{1, \frac{P(y)}{P(x)}\right\}.
\end{equation}

Since the target distribution \(P(x)\) only appears as a ratio, normalizing factors can be ignored.

\subsubsection{Potential for Bayes'-MCMC when sampling from analytic distributions}
\label{sec:org1e8daba}
How can we use formulations of Metropolis-Hastings-MCMC algorithms designed to sample from
posteriors when want to sample from probability distribution with an easy analytical expression?

Algorithms for sampling from a posterior sample from
$$\rho(u) \propto \rho_0(u) \exp(-\Phi(u)),$$
where \(\rho_0\) is the prior and \(\exp(-\Phi(u))\) is the likelihood. Normally, we have an
efficient way to compute the likelihood.

When we have an efficient way to compute the posterior \(\rho\) and we want to sample from it,
the potential to do that is:
$$\Phi(u) = \ln(\rho_0(u)) - \ln(\rho(u)),$$
where an additive constant from the normalization was omitted since only potential differences
are relevant.

When working with a Gaussian prior \(\N{0}{\C}\), the potential takes the form
$$\Phi(u) = -\ln{\rho(u)} - \frac{1}{2} \norm{\C^{-1/2}u}^2.$$

When inserting this into the acceptance probability for the standard random walk MCMC given
in formula (1.2) in \cite{cotter_mcmc_2013}, the two Gaussian-expressions cancel, as do the
logarithm and the exponentiation, leaving the simple acceptance described in \ref{eqn:acceptance_simple}.

This cancellation does not happen when using the pCN-Acceptance probablity. This could
explain the poorer performance of pCN when directly sampling a probablity distribution.

\subsubsection{Acceptance Probabilities for different MCMC Proposers}
\label{sec:orge993e6f}
Start from Bayes' formula and rewrite the likelyhood \(\text{L}(u)\) as \(\exp(-\Phi(u))\) for
a positive scalar function \(\Phi\) called the potential:
$$\frac{\rho(u)}{\rho_o(u)} \propto \exp(\Phi(u)).$$
Assuming our prior to be a Gaussian (\(\mu_0 \sim \N{0}{\C}\)).

Then $$\rho(u) \propto \exp\left( -\Phi(u) + \frac{1}{2} \norm{C^{-1/2}u}^2 \right),$$
since \(u^T C^{-1} u = (C^{-1/2} u)^T(C^{-1/2} u) = \langle C^{-1/2}u, C^{-1/2}u \rangle = \norm{C^{-1/2} u}^2\),
where in the first equality we used \(C\) being symmetric.

This is formula (1.2) in \cite{cotter_mcmc_2013} and is used in the acceptance probability for
the standard random walk (see also \hyperref[sec:org42d142b]{Acceptance Probability for Metropolis-Hastings})

\(\C^{-1/2}u\) makes problems in infinite dimensions.

Todo: Why exactly is the second term (from the prior) cancelled when doing pCN?
\subsubsection{Different formulations of multivariate Gaussians}
\label{sec:org3b8b514}
Is an RV \(\xi \sim \N{0}{C}\) distributed the same as \(C^{1/2}\xi_0\), with \(\xi_0 \sim \N{0}{\I}\)?

From wikipedia: Affine transformation \(Y = c + BX\) for \(X \sim \N{\mu}{\Sigma}\) is also a Gaussian
\(Y \sim \N{c + B\mu}{B\Sigma B^T}\). In our case \(X \sim \N{0}{\I}\), so \(Y \sim \N{0}{C^{1/2}\I {C^{1/2}}^{T}} = \N{0}{C}\),
since the covariance matrix is positive definite, which means it's square root is also positive definite
and thus symmetric.

On second thought, it also follows straight from the definition:
$$
      \mathbf{X} \sim \N{\mu}{\Sigma}
      \Leftrightarrow
      \exists \mu \in \R^k, A \in \R^{k \cross l}
        \text{ s.t. }
        \mathbf{X} = \mu + A\mathbf{Z}
        \text{ with } \mathbf{Z}_n \sim \N{0}{1} \text{ i.i.d}
    $$
where \(\Sigma = AA^T\).
\subsubsection{Autocorrelation of non-centered distributions}
\label{sec:orgf7b0750}

A common definition of the autocorrelation function of a series \(\{X_t\}\) is (cite something here?)

\begin{equation}
\label{eqn:def_ac}
R(\tau) = \E{X_t X_{t+\tau}^*},
\end{equation}

which can be normalized by \(\tilde{R}(\tau) = R(\tau) / R(0)\) \footnote{Since we're only working with real numbers, the complex conjugate in the definition will
be dropped from now on.}.

For calculating \(R\) of a finite series \(\{X_t\}_{t=1}^{T}\), the series can either be
zero-padded or the summation limits adjusted accordingly:

\begin{equation}
R(\tau) = \sum_{t=1}^{T-\tau} X_t X_{t+\tau} \text{  for } \tau < T
\end{equation}

This seems to be the definition that is used in the function \href{https://numpy.org/doc/1.18/reference/generated/numpy.correlate.html}{\texttt{np.correlate}}:
\texttt{c\_\{av\}[k] = sum\_n a[n+k] * conj(v[n])} (where we get autocorrelation for \texttt{a=v=x}).

This gives the expected result for uniformly random noise in \([-1, 1]\). However, when shifting
the same distribution by a constant factor to get uniformly random noise in \([0, 2]\), the
autocorrelation decays approximately linearly: \ref{fig:ac_uni}.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/ac_theory.png}
\caption{\label{fig:ac_uni}
Autocorrelation function of the same signal \(\{X_t \sim \mathcal{U}([0,2])\}\), once computed with \texttt{np.correlate} on the original series (uncentered), and once for \(\{X_t - 1\}\) (centered).}
\end{figure}

To see why this happens, split up the signal into its mean plus a mean-zero pertubation:
\(X_t = \overline{X} + \tilde{X}_t\), where \(\overline{X} = \E{X}\) and \(\E{\tilde{X}} = 0\).
The normalized autocorrelation is then:

\begin{align}
\tilde{R}(\tau) =& \frac{\sum_{t=1}^{T-\tau} X_t X_{t+\tau}}
                        {\sum_{t=1}^{T} X_t^2} \\
                =& \frac{\sum_{t=1}^{T-\tau} (\overline{X} + \tilde{X}_t) (\overline{X} + \tilde{X}_{t+\tau})}
                        {\sum_{t=1}^{T} (\overline{X} + \tilde{X}_t)^2} \\
                =& \frac{(T-\tau) \overline{X}^2 + \overline{X} \sum_{t=1}^{T-\tau} (\tilde{X}_t + \tilde{X}_{t+\tau}) + \sum_{t=1}^{T-\tau}\tilde{X}_t \tilde{X}_{t+\tau}}
                        {T \overline{X}^2 + 2 \overline{X} \sum_{t=1}^T \tilde{X}_t + \sum_{t=1}^T \tilde{X}_t^2} \\
                =& \frac{(T-\tau) \overline{X}^2}
                        {T(\overline{X}^2 + \text{var}(X))},
\end{align}

where the last equality holds because
\begin{itemize}
\item \(\lvert\sum_{t=1}^{T-\tau} (\tilde{X}_t + \tilde{X}_{t+\tau})\rvert < \epsilon\) and \(\lvert\sum_{t=1}^T \tilde{X}_t \rvert < \epsilon\)
when \(T >> \tau\) by the weak law of large numbers
\item \(\sum_{t=1}^{T-\tau}\tilde{X}_t \tilde{X}_{t+\tau} = R(\tau) = 0\) for \(\tau \neq 0\) and X "uncorrelated"
\item \(\sum_{t=1}^T \tilde{X}_t^2 = T \cdot \text{var}(\tilde{X}) = T \cdot\text{var}(X)\)
\end{itemize}

This is a linear function in \(\tau\), which is what we see in the plots (plus quite some noise).

For \(\overline{X} >> \text{var}(X)\), we get \(\tilde{R}(\tau) = 1 - \tau / T\), which explains nicely
why in the "uncentered" autocorrelation always linearly decays to 0, independently of the signal length \(T\).

Considering these points, the python-function that computes the autocorrelation we're actually interested
in \footnote{The function I'm describing here is called auto-covariance function \(K_{XX} = \E{(X_t - \mu) (X_{t+\tau} - \mu)^*}\).} looks like this:

\begin{minted}[]{python}
def autocorr(x):
    x_centered = x - np.mean(x)
    result = np.correlate(x_centered, x_centered, mode='full')
    # numpy computes the correlation from -\infty to +\infty
    result = result[-len(x):]
    # normalize the result
    return result / result[0]
\end{minted}

Much of this hassle could be avoided when the expectation value in the definition of the autocorrelation
\ref{eqn:def_ac} would be computed correctly (not just "a posteriori" in the normalizing step with
a much too large factor for bigger values of \(\tau\)). However, this is not possible while still taking
advantage of the huge speedup of doing the convolution operation in Fourier space.

\section{Framework/Package Structure}
\label{sec:org822fcde}
The framework is designed to support an easy use case:
\begin{minted}[]{python}
proposer = StandardRWProposer(beta=0.25, dims=1)
accepter = AnalyticAccepter(my_distribution)
rng = np.random.default_rng(42)
sampler = MCMCSampler(rw_proposer, accepter, rng)

samples = sampler.run(x_0=0, n_samples=1000)
\end{minted}

There is only one source of randomness, shared among all classes and supplied by the user.
This facilitates reproducability.

Tests are done with \texttt{pytest}.
\subsection{Distributions}
\label{sec:org576c10d}
A class for implementing probability distributions.
\begin{minted}[]{python}
class DistributionBase(ABC):
    @abstractmethod
    def sample(self, rng):
        """Return a point sampled from this distribution"""
        ...
\end{minted}

The most important realisation is the \texttt{GaussianDistribution}, used
in the proposers.

\begin{minted}[]{python}
class GaussianDistribution(DistributionBase):
    def __init__(self, mean=0, covariance=1):
        ...

    def sample(self, rng):
        ...

    def apply_covariance(self, x):
        ...

    def apply_sqrt_covariance(self, x):
        ...

    def apply_precision(self, x):
        ...

    def apply_sqrt_precision(self, x):
        ...
\end{minted}

The design of this class is based on the implementation in \href{http://muq.mit.edu/master-muq2-docs/CrankNicolson\_8py\_source.html}{muq2}. The \texttt{precision} / \texttt{sqrt\_precision}
is implemented through a Cholesky decomposition, computed in the constructor. This makes
applying them pretty fast (\(\mathcal{O}(n^2)\)).

At the moment the there is one class for both scalar and multivariate Gaussians. This
introduces some overhead as it has to work with both \texttt{float} and \texttt{np.array}. Maybe two
seperate classes would be better.

Also, maybe there is a need to implement a Gaussian using the Karhunen-Loéve-Expansion?
\subsection{Potentials}
\label{sec:org843772d}
A class for implementing the potential resulting from rewriting the likelihood as
$$\text{L}(u) = \exp(- \Phi(u)).$$

\begin{minted}[]{python}
class PotentialBase(ABC):
"""
    Potential used to express the likelihood;
    d mu(u; y) / d mu_0(u) \propto L(u; y)
    Write L(u; y) as exp(-potential(u; y))
    """
    @abstractmethod
    def __call__(self, u):
        ...

    @abstractmethod
    def exp_minus_potential(self, u):
        ...
\end{minted}

The two functions return \(\Phi(u)\) and \(\exp(-\Phi(u))\) respectively. Depending on the
concrete potential, one or the other is easier to compute.

Potentials are used in the accepters to decide the relative weight of different configurations.
They use the \texttt{\_\_call\_\_}-method to do that. Especially for high-dimensional error-terms, the
value of the pdf of the error term can become very small, so it is important to implement this
computing the logpdf directly instead of manually exponentiating and running into issues with
floating point number limitations.

\subsubsection{AnalyticPotential}
\label{sec:orgaa8b3f0}

This potential is used when sampling from an analytically computable probability distribution,
i.e. a known posterior. In this case
$$\exp(-\Phi(u)) = \frac{\rho(u)}{\rho_0(u)},$$
see \url{theory.org}
\subsubsection{EvolutionPotential}
\label{sec:org7aec9ca}

This potential results when sampling from the model-equation
$$y = \G{u} + \eta,$$
with \(\eta \sim \rho\). The resulting potential can be computed as
$$\exp(-\Phi(u)) = \rho(y - \G{u}).$$

\subsection{Proposers}
\label{sec:org0d955a8}

Propose a new state \(v\) based on the current one \(u\).

\begin{minted}[]{python}
class ProposerBase(ABC):
    @abstractmethod
    def __call__(self, u, rng):
        ...
\end{minted}

\subsubsection{StandardRWProposer}
\label{sec:org27dc4da}

Propose a new state as
$$v = u + \sqrt{2\delta} \xi,$$
with either \(\xi \sim \N{0}{\I}\) or \(\xi \sim \N{0}{\C}\) (see section 4.2 in \cite{cotter_mcmc_2013}).

This leads to a well-defined algorithm in finite dimensions.
This is not the case when working on functions (as described in section 6.3 in \cite{cotter_mcmc_2013})

\subsubsection{pCNProposer}
\label{sec:org48d1a5c}

Propose a new state as
$$v = \sqrt{1-\beta^2} u + \beta \xi,$$
with \(\xi \sim \N{0}{\C}\) and \(\beta = \frac{8\delta}{(2+\delta)^2} \in [0,1]\)
(see formula (4.8) in \cite{cotter_mcmc_2013}).

This approach leads to an improved algorithm (quicker decorrelation in finite dimensions,
nicer properties for infinite dimensions)(see sections 6.2 + 6.3 in \cite{cotter_mcmc_2013}).

The wikipedia-article on the Cholesky-factorization mentions the use-case of obtaining a
correlated sample from an uncorrelated one by the Cholesky-factor. This is not implemented here.
\subsection{Accepters}
\label{sec:orgb0d43fe}

Given a current state \(u\) and a proposed state \(v\), decide if the new state is accepted or rejected.

For sampling from a distribution \(P(x)\), the acceptance probability for a symmetric proposal is
\(a = \text{min}\{1, \frac{P(v)}{P(u)}\}\)
(see \url{theory.org})

\begin{minted}[]{python}
class ProbabilisticAccepter(AccepterBase):
    def __call__(self, u, v, rng):
        """Return True if v is accepted"""
        a = self.accept_probability(u, v)
        return a > rng.random()

    @abstractmethod
    def accept_probability(self, u, v):
        ...
\end{minted}

\subsubsection{AnalyticAccepter}
\label{sec:org6292489}

Used when there is an analytic expression of the desired distribution.

\begin{minted}[]{python}
class AnalyticAccepter(ProbabilisticAccepter):
    def accept_probability(self, u, v):
        return self.rho(v) / self.rho(u)
\end{minted}

\subsubsection{StandardRWAccepter}
\label{sec:org1a0e971}

Based on formula (1.2) in \cite{cotter_mcmc_2013}:
$$a = \text{min}\{1, \exp(I(u) - I(v))\},$$ with
$$I(u) = \Phi(u) + \frac{1}{2}\norm{\C^{-1/2}u}^2$$.

See also \url{theory.org}.

\subsubsection{pCNAccepter}
\label{sec:orgdcdbf83}

Works together with the \hyperref[sec:org48d1a5c]{pCNProposer} to achieve the simpler expression for the acceptance
$$a = \text{min}\{1, \exp(\Phi(u) - \Phi(v))\}.$$

\subsubsection{CountedAccepter}
\label{sec:orgeef96d9}

Stores and forwards calls to an "actual" accepter. Counts calls and accepts and is used for
calculating the acceptance ratio.

\subsection{Sampler}
\label{sec:org9c60534}

The structure of the sampler is quite simple, since it can rely heavily on the functionality
provided by the Proposers and Accepters.

\begin{minted}[]{python}
class MCMCSampler:
    def __init__(self, proposal, acceptance, rng):
        ...

    def run(self, u_0, n_samples, burn_in=1000, sample_interval=200):
        ...

    def _step(self, u, rng):
        ...
\end{minted}

\section{Results}
\label{sec:orga7d3aa5}
\subsection{Analytic sampling from a bimodal Gaussian}
\label{sec:orgee31d86}
\subsubsection{Setup}
\label{sec:org692d003}

Attempting to recreate the "Computational Illustration" from \cite{cotter_mcmc_2013}. They use,
among other algorithms, pCN to sample from a 1-D bimodal Gaussian
$$\rho \propto (\N{3}{1} + \N{-3}{1}) \mathds{1}_{[-10,10]}.$$
Since the density estimation framework for a known distribution is not quite clear to me from
the paper, I don't expect to perfectly replicate their results.

They use a formulation of the prior based on the Karhunen-Loéve Expansion that doesn't make
sense to me in the 1-D setting (how do I sum infinite eigenfunctions of a scalar?).

The potential for density estimation described in section is also not clear to me (maybe for
a similar reason? What is \(u\) in the density estimate case?).

I ended up using a normal \(\N{0}{1}\) as a prior and the potential described \hyperref[sec:org1e8daba]{before}, and
compared the following samplers:
\begin{itemize}
\item (1) \href{code.org}{\texttt{StandardRWProposer}} (\(\delta=0.25\)) + \href{code.org}{\texttt{AnalyticAccepter}}
\item (2) \href{code.org}{\texttt{StandardRWProposer}} (\(\delta=0.25\)) + \href{code.org}{\texttt{StandardRWAccepter}}
\item (3) \href{code.org}{\texttt{pCNProposer}} (\(\beta=0.25\)) + \href{code.org}{\texttt{pCNAccepter}}
\end{itemize}

The code is in \href{scripts/analytic.py}{\texttt{analytic.py}}.

\subsubsection{Result}
\label{sec:orgd122489}

All three samplers are able to reproduce the target density \ref{fig:hist_bimodal}

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/bimodal_density_combined.png}
\caption{\label{fig:hist_bimodal}
Burn-in: 1000, sample-interval: 200, samples: 500}
\end{figure}

The autocorrelation decays for all samplers: \ref{fig:ac_bimodal}. However, the pCN doens't
do nearly as well as expected. This could be the consequence of the awkward
formulation of the potential or a bad prior.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/analytic_standard_rw_pCN_50_5000.png}
\caption{\label{fig:ac_bimodal}
AC of bimodal distribution. pCN takes forever to decorrelate}
\end{figure}

\subsection{Bayesian inverse problem for \(\G{u} = \langle g,u \rangle\)}
\label{sec:org96b6cd4}
For \(\G{u} = \langle g,u \rangle\) the resulting posterior under a Gaussian prior
is again a Gaussian. The model equation is
$$y = \G{u} + \eta$$
with:
\begin{itemize}
\item \(y \in \R\)
\item \(u \in \R^n\)
\item \(\eta \sim \N{0}{\gamma^2}\) for \(\gamma \in \R\)
\end{itemize}

A concrete realization with scalar \(u\):
\begin{itemize}
\item \(u = 2\)
\item \(g = 3\)
\item \(\gamma = 0.5\)
\item \(y=6.172\)
\item prior \(\N{0}{\Sigma_0=1}\)
\end{itemize}
leads to a posterior with mean
\(\mu = \frac{(\Sigma_0g)y}{\gamma^2 + \langle g, \Sigma_0g \rangle} \approx 2\),
which is what we see when we plot the result \ref{fig:stuart_21_density}.
The pCN-Sampler with \(\beta = 0.25\) had an acceptance rate of 0.567.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/stuart_example_21_n=1_N=5000.png}
\caption{\label{fig:stuart_21_density}
\(N=5000, \mu \approx 2\)}
\end{figure}

For \(n>2\), the resulting posterior can not be plotted anymore. However, it is still Gaussian
with given mean \& covariance. Can just compare the analytical values to the sample values.
Verify that the error decays like \(\frac{1}{\sqrt{N}}\).
\subsection{Bayesian inverse problem for \(\G{u} = g (u + \beta u^3)\)}
\label{sec:orgdd4abf6}
Since the observation operator is not linear anymore, the resulting posterior is not
Gaussian in general. However, since the dimension of the input \(u\) is 1, it can
still be plotted.

The concrete realization with:
\begin{itemize}
\item \(g = [3, 1]\)
\item \(u = 0.5\)
\item \(\beta = 0\)
\item \(y= [1.672, 0.91]\)
\item \(\gamma = 0.5\)
\item \(\eta \sim \N{0}{\gamma^2 I}\)
\item prior \(\N{0}{\Sigma_0=1}\)
\end{itemize}
however leads to a Gaussian thanks to \(\beta = 0\). The mean is
\(\mu = \frac{\langle g,y \rangle}{\gamma^2 + |g|^2} \approx 0.58\). Plot: \ref{fig:stuart_22_density}

The pCN-Sampler with \(\beta = 0.25\) (different beta) had an acceptance rate of 0.576.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/stuart_example_22_q=2_N=5000.png}
\caption{\label{fig:stuart_22_density}
\(N=5000, \mu \approx 0.58\)}
\end{figure}

For \(\beta \neq 0\), the resulting posterior is not a Gaussian. Still \(n=1\), so it can be
plotted. Just numerically normalize the analytical expression of the posterior?

\subsection{Lorenz96 model}
\label{sec:orgf490a6b}
\subsubsection{Model}
\label{sec:org5c3047d}
\paragraph{Based on:}
\label{sec:orga979cce}

Properly cite this!


Lorenz, E. N. (1996). Predictability—A problem partly solved. In Reprinted in T. N. Palmer \& R. Hagedorn (Eds.), Proceedings Seminar on
Predictability, Predictability of Weather and Climate, Cambridge UP (2006) (Vol. 1, pp. 1–18). Reading, Berkshire, UK: ECMWF.

\paragraph{Equation}
\label{sec:orgefe6ac8}

A system of ODEs, representing the coupling between slow variables \(X\) and fast, subgrid
variables \(Y\). The system is used in \cite{schneider_earth_2017} to illustrate different
algorithms for earth system modelling.

\begin{equation}
\label{eqn:lorenz_X}
  \dv{X_k}{t} =                 - X_{k-1}(X_{k-2} - X_{k+1}) - X_k + F - hc \bar{Y}_k
\end{equation}

\begin{equation}
\label{eqn:lorenz_Y}
  \frac{1}{c} \dv{Y_{j,k}}{t} = -bY_{j+1,k}(Y_{j+2,k} - Y_{j-1, k}) - Y_{j,k} + \frac{h}{J}X_k
\end{equation}

\begin{itemize}
\item \(X = [X_0, ..., X_{K-1}] \in \R^K\)
\item \(Y = [Y_{j, 0} | ... | Y_{j, K-1}] \in \R^{J \cross K}\) \\
\(Y_{j,k} = [Y_{0,k}, ..., Y_{J-1,k}] \in  \R^J\)
\item \(\bar{Y}_k = \frac{1}{J}\sum_j Y_{j,k}\)
\item periodic: \(X_K = X_0\), \(Y_{J,k} = Y_{0,k}\)
\item Parameters \(\Theta = [F, h, c, b]\)
\item \(h\): coupling strength
\item \(c\): relative damping
\item \(F\): external forcing of the slow variables (large scale forcing)
\item \(b\): scale of non-linear interaction of fast variables
\item \(t = 1 \Leftrightarrow 1\) day (simulation duration is given in days)
\end{itemize}

\subparagraph{\(b\) or \(J\)?}
\label{sec:org41800a2}
In the original paper, the equations are given in a different form, namely all
explicit occurences of \(J\) above (in the fast-slow interaction) are replaced by
\(b\). Since in both concrete realizations (1996 \& 2017) are identical and conviniently
have \(b=J=10\), the difference doesn't lead to different results for that setup.

\subparagraph{"Looking ahead" vs. "Looking back"}
\label{sec:org7f94283}
Comparing nonlinearity terms
$$-X_{k-1}(X_{k-2} - X_{k+1})$$
$$-bY_{j+1,k}(Y_{j+2,k} - Y_{j-1, k})$$
for a given \(Y_{k}\), does the "direction" of the \(Z_{k\pm 1}Z_{k\pm 2}\) (\(Z=X,Y\)) matter?

I don't think so, since the interaction with the other variable is only via point-value
and average, and the nonlinearity is periodic.

A bit more formally:
The PDE is invariant under "reversing" of the numbering:
\(Y_{j,k} \rightarrow Y_{J-j,k}\) which is the same as switching \(+ \leftrightarrow -\) in
the only "asymmetric" term.

Addendum 2 days later: Need to define more clearly what it means for the direction to
\uline{matter}. In the original paper on page 12, it is described how "active areas [..] propagate
slowly eastward", while "convective activity tends to propagate westward within the active
areas" (rephrased from paper). The paper also explicitly mentions the signs of the subscripts
in that context. So some characteristics of the solution are definitely affected.
What about the stuff we care about (statistical properties, chaotic behaviour)?


\paragraph{Properties}
\label{sec:org3353306}

For \(K=36\), \(J=10\) and \(\Theta = [F, h, c, b] = [10, 1, 10, 10]\) there is chaotic behaviour.

\subparagraph{Energy}
\label{sec:orgfcfa443}

The nonlinearities conserve the energies within a subsystem:
\begin{itemize}
\item \(E_X = \sum_k X_k^2\)

\(\frac{1}{2} \dv{(\sum_k X_k^2)}{t} =
         \sum_k X_k \dv{X_k}{t} =
         -\sum_k (X_k X_{k-1} X_{k-2} - X_{k-1} X_{k} X_{k+1}) =
         0\),

where the last equality follows from telescoping + periodicity
\item \(E_{Y_k} = \sum_j Y_{j,k}^2\)

which follows analogously to the \(X\) -case
\end{itemize}

The interaction between fast and slow variables conserves the total energy:
\begin{itemize}
\item \(E_{T} = \sum_k (X_k^2 + \sum_j Y_{j,k}^2)\)

\(\frac{1}{2} \dv{E_{T}}{t} =
         \sum_k X_k \dv{X_k}{t} + \sum_j Y_{j,k} \dv{Y_j,k}{t} =
         \sum_k X_k (- \frac{hc}{J} \sum_j Y_{j,k}) + \sum_j Y_{j,k} (\frac{hc}{J} X_k) =
         \sum_k - \frac{hc}{J} X_k (\sum_j Y_{j,k} + \frac{hc}{J} X_k (\sum_j Y_{j,k})) = 
         0\)
\end{itemize}

In the statistical steady state, the external forcing \(F\) (as long as its positive) balances
the dampling of the linear terms.

\subparagraph{Averaged quantities}
\label{sec:orge1726ff}

$$\expval{\phi} = \frac{1}{T} \int_{t_0}^{t_0 + T} \phi(t) \dd{t}$$ (or a sum over discrete values)

Long-term time-average in the statistical steady state: \(\expval{\cdot}_{\infty}\)

\begin{itemize}
\item \begin{equation}
\label{eqn:equilibrium_X}
   \expval{X_k^2}_\infty = F \expval{X_k}_{\infty} - hc \expval{X_k\bar{Y_k}}_\infty \forall k
\end{equation}
(multiply \(X\) -equation by \(X\), all \(X_k\) s are statistically equivalent, \(\dv{\expval{X}}{t} = 0\) in steady state)
\item \begin{equation}
\label{eqn:equilibrium_Y}
  \expval{\bar{Y_k^2}}_{\infty} = \frac{h}{J} \expval{X_k \bar{Y_k}}_{\infty} \forall k
\end{equation}
\end{itemize}

\subparagraph{(Quasi) Ergodicity}
\label{sec:orge25161e}

Whether chaotic regions of the phase space of a system are ergodic seems not be an easy question
to answer (citation needed probably) \footnote{Are there any inaccessible regions in phase space
for the Lorenz system? I can't think of any. However, there seem to be "traps" that take the
system out of it's chaotic behaviour (\(X_i = c\), \(Y_i=a\)). These destroy ergodicity.
Are they somehow "measure 0" or something?} Are there any inaccessible regions in phase space
for the Lorenz system? I can't think of any. However, there seem to be "traps" that take the
system out of it's chaotic behaviour (\(X_i = c\), \(Y_i=a\)). These somehow destroy ergodicity.
Are they somehow "measure 0" or something?)/. However, for the purposes of this section (which deals with
finite time anyway), it is enough to assert that

for the Lorenz system, for sufficiently long times, the time-average converges to the
"space-average" over phase-space:

\begin{equation}
\label{eqn:lorenz_ergodicity}
   \expval{f}_{\infty} = \lim_{T \to \infty} \int_0^T f(Z(t)) \dd{t} = \int_{\R^{K(J+1)}} f(x) \rho(x) \dd{x}
\end{equation}

where \(Z(t)\) is a phase space trajectory of the system and \(\rho(x)\) is the probaility of the
system in the statistical steady state to be in state \(x\).

One sufficiently long simulation of the system gives information about all accessible \footnote{Here a more precise definition of ergodicity of the system would help out. What I mean
is "all sensible initial conditions".} initial conditions.
As a consequence, as long as the integration time of the system is "long enough", the chosen initial
condition is meaningless and can even vary without changing the behaviour of the observation operator.

\subsubsection{Model implementation}
\label{sec:org2769342}

Implementing the model in python and using a locally 5-th order RK solver yields the following
results (inital conditions are just uniformly random numbers in \([0,1)\) since they don't matter
for the long-term evolution of the chaotic system):

\paragraph{Reproducting the results of the original paper}
\label{sec:org0889579}
Running the setup with \(K=36, J=10, (F, h, c, b) = (10, 1, 10, 10)\) gives the following states
\ref{fig:lorenz96_combined},
which qualitatively agree with the results from Lorenz.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/lorenz96_combined.png}
\caption{\label{fig:lorenz96_combined}
System around \(T=20\)}
\end{figure}

The decay of the linear term and the forcing of the slow variables balance out after reaching the
steady state, however there is a much bigger fluctuation in the energy than expected \ref{fig:lorenz_energy}.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/lorenz96_energies.png}
\caption{\label{fig:lorenz_energy}
Energies in the system. \(E_X >> E_{Y_k} > 0\)}
\end{figure}

\paragraph{Equilibrium averages}
\label{sec:org0b6d8ac}
Analysis suggests certain long-term averages to be equal in the equilibrium.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/equilibrium_error_n=10.png}
\caption{\label{fig:lorenz_rmse}
RMSE for long-term averages \ref{eqn:equilibrium_X} and \ref{eqn:equilibrium_Y}. Averaged over 10 runs}
\end{figure}

\subsubsection{MCMC}
\label{sec:orgeeaa09e}
General point: The \texttt{RK45} method uses a predictor/corrector step and thus does non-uniform timesteps.
However, in the following I compute time-averages with a simple \texttt{np.mean}, ignoring the different
length of timesteps. It would be not impossible to write my own \texttt{time\_average(y, t)}-function that
takes the non-uniform timesteps into account. However I'm not sure how necessary this is, considering
a forward-integration takes \(\mathcal(2000)\) timesteps, so I suspect that differences are washed out
a bit?

\paragraph{Setup}
\label{sec:orgfaae50a}
Denote the Lorenz-96 system \ref{eqn:lorenz_X}, \ref{eqn:lorenz_Y} with parameters \(\tilde{u} = [F, h, c, b]\) as
\(\mathcal{M}[\tilde{u}]\). It acts on the initial condition \(z_0 = [X_0, Y_0] \in \R^{K(J+1)}\) to evolve
the system for \(N_t\) timesteps and generate the phase space trajectory
\(Z = \left[ \smash{{}^{X_1}_{Y_1}} | \cdots | \smash{{}^{X_{N_t}}_{Y_{N_t}}}  \right] \in
   \R^{K(J+1) \cross N_t}\):
$$Z = \mathcal{M}[\tilde{u}] z_0$$

Define the "moment function" \(f(z): \R^{K(J+1)} \to \R^{5K}\)

\begin{align}
  f(z) &=
  \begin{bmatrix}
    X \\
    \bar{Y} \\
    X^2 \\
    X \bar{Y} \\
    \overline{Y^2}
  \end{bmatrix}
\end{align}

The MCMC-Algorithm then samples based on:

$$\expval{f}_\infty = \expval{f}_T(u) + \eta$$
with:
\begin{itemize}
\item \(\expval{f}_\infty \approx \expval{f}_{T_r}\) with \(T_r >> T\) over a simulation \(\mathcal{M}[u^*] z_0\)
\item \(\expval{f}_T(u)\) the time average over a simulation \(\mathcal{M}[u_p + u] z_0\)
\item Due to the ergodic properties of \(\mathcal{M}\) \ref{sec:orge25161e} , it doesn't really matter what \(z_0\) is
\item The parameter vector comes in many different variations:
\begin{itemize}
\item \(u^* \in \R^4_{\geq 0}\): true underlying parameters, used to compute the "data"
\item \(u_p \in \R^4_{\geq 0}\): mean of the prior
\item \(u \in \R^4\): pertubations to the prior mean, the actual input to the observation operator
\end{itemize}
\item \(\eta \sim \N{0}{\Sigma}\), where \(\Sigma = r^2 [\text{var}(f)_{T_r}]\),
where \(r \in \R\) is the "noise level"
\end{itemize}

\begin{enumerate}
\item The parameter vector \(u\)
\label{sec:orgc0df6cf}

The theoretical background assumes the prior to be a centered Gaussian (\(\mu = 0\)).
Specifically, it matters during the proposal step, where the step is taken either with
scaled sample from the prior or from a centered Gaussian with the covariance of the prior.
A compromise would be to just ignore a nonzero prior-mean in the proposal, however I'm not
sure if such a prior has other effects that invalidate the algorithm.

\item "Noise level"
\label{sec:org403e6b7}

\(r\) is scaling of covariance matrix of noise term. This in turn is just step-width in proposal.

TODO: Verify by checking acceptance rate for different noise levels
\end{enumerate}

\subparagraph{Concrete parameters}
\label{sec:org185ad34}

The MCMC-Simulation was carried  out with the following parameters:

\begin{itemize}
\item \(K = 6, J = 4\)
\item Reference Simulation to get \(\expval{f}_\infty\) and \(\Sigma\):
\begin{itemize}
\item \(u^* = [F^*, h^*, c^*, b^*]= [10, 10, 1, 10]\)
\item \(T_r = 500\)
\end{itemize}
\item Noise \(\eta \sim \N{0}{\Sigma}\) with \(\Sigma = r^2 \text{diag}(\text{var}(f_{T_r})) \in \R^{5K \cross 5K}\)
\item Noise level \(r= 0.5\)
\item Prior \(\N{u_p}{\Sigma_0}\)
\begin{itemize}
\item \(u_p = [F_0, h_0, b_0] = [12, 8, 9]\)
\item \(\Sigma_0 = \text{diag}([10, 1, 10])\)
\item \(c\) was excluded from the sampling since it is very hard to estimate ("bad statistics")
\item The prior was chosen closer to the true value to make the job of the algorithm easier
\end{itemize}
\item Sampling with \emph{pCN} proposer and acccepter with \(\beta = 0.25\)
\begin{itemize}
\item Evaluating the observation operator with a model-simulation of \(T=20\)
\item Start sampling very close to true value: \(u_0 = [-1.9, 1.9, 0.9]\) so that \(u^* \approx u_p + u_0\)
\item This means we can use a short burn-in of 100
\item Sample \(N = 2500\) with a sample-interval of 2
\item The sample interval of 2 is very short, especially considering the long correlation time see below.
But 2 is also what they used in the ESM paper.
\end{itemize}
\end{itemize}

\paragraph{Result}
\label{sec:org5484a82}

\subparagraph{Density plot for posterior}
\label{sec:orgc9c9aa6}

The resulting density plots show a improvement from the prior towards the true value \ref{fig:lorenz_densities}.
The estimation of the parameter \(F\) seems to be easier than \(b\), where the prior and the
posterior seem pretty much identical.

This slight improvement is however not unexpected, as the simulations I've done are much shorter than
the ones in \cite{schneider_earth_2017} (\(K, J) = (6,4)\) vs \((36, 10)\), \(T = 20\) vs 100, \(T_r = 500\) vs 46,416)

Should I do some more analysis here, like reporting sample means and covariances to compare
posterior/prior not just visually?

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/combined_K=6_J=4_T=20_r=0.5.png}
\caption{\label{fig:lorenz_densities}
Prior and Posteriors after a 5000 sample MCMC run}
\end{figure}

\subparagraph{ACF}
\label{sec:orge0ca4c0}

The autocorrelation decays for all three variables. As expected from the accuracy of the posteriors,
the autocorrelation of \(F\) decays much faster than that of \(b\). This simulation was done with a
value of \(\beta=0.5\), which controls the "step size" of the proposer, and resulted in an acceptance
rate of around \(0.6\). The value for \(\beta\) can now be tuned in such a way to get the fastest decay
of the autocorrelation, which happens when the steps taken during sampling are big enough to
quickly decorrelate the chain, while not being so big that the accepter declines too many of the steps.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/lorenz_ac_avg_K=6_J=4_T=20_r=0.5.png}
\caption{\label{fig:lorenz_acF}
Autocorrelation of during the MCMC sampling. The functions are averaged over ten distinct parts of the chain}
\end{figure}
\subsection{Perturbed Riemann problem for Burgers' equation}
\label{sec:org8b17655}
\subsubsection{Model}
\label{sec:org96dadcb}
\paragraph{Burgers' Equation}
\label{sec:org383b609}

Blabla
\paragraph{Riemann Problem}
\label{sec:orgf3cea05}

Blabla
\paragraph{Rusanov FVM}
\label{sec:orgb22866a}

Blabla
\subsubsection{MCMC}
\label{sec:org906dbbd}
\paragraph{Setup}
\label{sec:orgdb8ac28}

\begin{center}
\includegraphics[width=.9\linewidth]{Burg_BInv.pdf}
\end{center}
\paragraph{Result}
\label{sec:org85b59be}

The evolution of the Markov chain is shown in this figure: \ref{fig:burgers_chain}

The autocorrelation in decaying not as fast as I could have hoped for \ref{fig:burgers_ac}.

The resulting posteriors look like this: \ref{fig:burgers_densities}. It is apparent from the investigation
of the Markov chain and the autocorrelation that a burn-in of 100 and a sample interval of 5 are both
too short to get uncorrelated samples from the steady state. Especially the too short burn-in is visible
in the posteriors.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/burgers_setup.png}
\caption{\label{fig:burgers_setup}
Setup for the MCMC experiment. The values for \(u\) at \(T=1\), once for the unperturbed Riemann problem, once for the ground truth of the simulation. The green rectangles are the measurement intvervals of the observation operator : \(\int_{x_i - 0.05}^{x_i + 0.05}u(x,1)\dd x\), \(x_i \in \{ -0.5, -0.25, 0.25, 0.5, 0.75 \}\).}
\end{figure}


\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/burgers_chain_b=0.25.png}
\caption{\label{fig:burgers_chain}
Evolution of the Markov chain with n=1100. The spinup is also shown here. The red value show the shock location for their respective \(\delta\), \(\sigma\) values, and the red intervals are the measurement intervals. The black lines are the underlying ground truth. It is apparent that a quite long spinup is necessary for the chain to arrive at a steady state.}
\end{figure}

\begin{center}
\includegraphics[width=.9\linewidth]{./figures/burgers_ac_b=0.25.png}
\label{fig:burgers_ac}
\end{center}

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/burgers_densities.png}
\caption{\label{fig:burgers_densities}
Posteriors of the MCMC-Simulation, obtained from the Chain shown above. burn\(_{\text{in}}\)=100, sample\(_{\text{interval}}\)=5.}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/burgers_densities_easy_prior.png}
\caption{\label{fig:burgers_densities_easy_prior}
The same setup as before, but the means of the priors are much closer to the ground truth}
\end{figure}

When the priors are much closer to the ground truth, the chain is able to find the minimum faster,
resulting in sharper posteriors \ref{fig:burgers_densities_easy_prior}. I guess this is just because
this cuts the burn-in time drastically, as we start basically with the correct \(u\).

With the current setup of measurement points
and the discontiuous nature of \(u\) (see this figure \ref{fig:burgers_setup}),
the "objective function value" is also "pretty discontinuous",
which gives the Markov chain a hard time moving towards the optimum (interpreting the steps as
a stochastic gradient descent).

This manifests itself in the very low acceptance ratio (\textasciitilde{}0.1), easily visible in the later parts of
the chain. This results in a pretty bad exploration of the state space around the steady state.
This could probably be "fixed" by using priors with smaller variance or by decreasing the \(\beta\) of the
MCMC-proposer (are these two equivalent? Not really I think, since a large \(\beta\) also "pulls the proposed states towards 0".
This effect would actually be a reason to require priors to be mean-0).

Getting the chain to take smaller steps (at the moment the characteristic stepsize is bigger than the region of the state-space we
want to explore (\(\beta \cdot \gamma = 0.025\) vs. 0.01 the measurement interval))
would however mean a much much longer burn-in, so the prior-means would have to be chosen closer to the true values.

\bibliographystyle{plain}
\bibliography{../papers/inverse_problems}
\end{document}
