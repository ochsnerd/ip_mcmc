% Created 2020-07-01 Mi 11:06
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage{minted}
\usepackage{physics}
\usepackage{dsfont}
\newcommand{\C}{{\mathcal{C}}}
\newcommand{\I}{{\mathcal{I}}}
\newcommand{\R}{{\mathbb{R}}}
\newcommand{\NN}{{\mathbb{N}}}
\newcommand{\G}[1]{{\mathcal{G} \left( #1 \right)}}
\newcommand{\E}[1]{{\mathop{\mathbb{E}}\left[ #1 \right]}}
\newcommand{\N}[2]{\mathcal{N}\left(#1,#2\right)}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}
\author{David Ochsner}
\date{\today}
\title{Markov Chain Monte Carlo for Inverse Problems}
\hypersetup{
 pdfauthor={David Ochsner},
 pdftitle={Markov Chain Monte Carlo for Inverse Problems},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 26.3 (Org mode 9.1.9)}, 
 pdflang={English}}
\begin{document}

\maketitle
\tableofcontents


\section{Theory}
\label{sec:org25adb04}
\subsection{Papers}
\label{sec:orgba76570}
\subsubsection{Stuart et al: Inverse Problems: A Bayesian Perspective \cite{stuart_inverse_2010}}
\label{sec:org97ef198}
Theoretical Background
\paragraph{Notation}
\label{sec:orgf81968c}
Central equation:
$$y = \G{u} + \eta$$
with:
\begin{itemize}
\item \(y \in \R^q\): data
\item \(u \in \R^n\): IC ("input to mathematical model")
\item \(\G{\cdot} :\R^n \to \R^q\): observation operator
\item \(\eta\): mean zero RV, observational noise (a.s. \(\eta \sim \N{0}{\C}\))
\end{itemize}
\subsubsection{Cotter et al: MCMC for functions \cite{cotter_mcmc_2013}}
\label{sec:org5db213f}
Implementation, MCMC in infinite dimensions
\subsubsection{Schneider et al: Earth System Modeling 2.0  \cite{schneider_earth_2017}}
\label{sec:org2ce08dd}
Example for MCMC on ODE
\subsection{Small results}
\label{sec:org09dc9b1}
\subsubsection{Gaussian in infinite dimensions}
\label{sec:org083ed37}
This section is quite a mess, maybe you could suggest a not-too-technical introduction
to infinite dimensional Gaussian measures?

Wiki: Definition of Gaussian measure uses Lesbesgue measure.
However, the Lesbesgue-Measure is not defined in an infinite-dimensional space (\href{https://en.wikipedia.org/wiki/Infinite-dimensional\_Lebesgue\_measure}{wiki}).

Can still define a measure to be Gaussian if we demand all push-forward measures via a
linear functional onto \(\R\) to be a Gaussian. (What about the star (E\(^{\text{*}}\), L\(_{\text{*}}\))
in the wiki-article? Are they dual-spaces?) (What would be an example of that? An example
for a linear functional on an inf-dims space given on wikipedia is integration.
What do we integrate? How does this lead to a Gaussian?)

How does this fit with the description in \cite{cotter_mcmc_2013}? -> Karhunenen-Loéve

What would be an example of a covariance operator in infinite dimensions?
The Laplace-Operator operates on functions, the eigenfunctions would be \(sin\), \(cos\) (I think?
This might not actually be so easy, see \href{https://en.wikipedia.org/wiki/Dirichlet\_eigenvalue}{Dirichlet Eigenvalues}). Are the eigenvalues
square-summable?

Anyway, when a inf-dim Gaussian is given as a KL-Expansion, an  example of a linear functional
given as \(f(u) = \langle \phi_i, u \rangle\) for \(\phi_i\) an eigenfunction of \(\C\), then I can see
the push-forward definition of inf-dim Gaussians satisfied. ( \(\C\) spd, so \(\phi_i\) s are
orthogonal, so we just end up with one of the KH-"components" which is given to be \(\N{0}{1})\).

The problem is not actually in \(\exp(-1/2x^T\C^{-1}x)\). What about \(\exp(-1/2\norm{\C^{-1/2}x})\)?

What about the terminology in \cite{cotter_mcmc_2013}? Absolutely continuous w.r.t a measure for
example?

How is the square root of an operator defined? For matrices, there seems to be a freedom in
choosing whether \(A = BB\) or \(A = BB^T\) for \(B = A^{1/2}\). The latter definition seems to
be more useful when working with Cholesky factorizations (cf. \url{https://math.stackexchange.com/questions/2767873/why-is-the-square-root-of-cholesky-decomposition-equal-to-the-lower-triangular-m}),
but for example in the wiki-article about the matrix (operator) square root (\url{https://en.wikipedia.org/wiki/Square\_root\_of\_a\_matrix}):
"The Cholesky factorization provides another particular example of square root, which should not be confused with the unique non-negative square root."

\subsubsection{Bayes' Formula \& Radon-Nikodym Derivative}
\label{sec:orgcff3acc}
Bayes' Formula is stated using the Radon-Nikodym Derivative in both \cite{cotter_mcmc_2013} and \cite{stuart_inverse_2010}:
$$\dv{\mu}{\mu_0} \propto \text{L}(u),$$
where \(\text{L}(u)\) is the likelihood.

Write the measures as \(\dd \mu = \rho(u)\dd u\) and \(\dd \mu_0 = \rho_0(u)\dd u\) with respect
to the standard Lesbesgue measure. Then we have
$$
    \int f(u) \rho(u) \dd u =
    \int f(u) \dd \mu(u) =
    \int f(u) \dv{\mu(u)}{\mu_0(u)} \dd \mu_0 =
    \int f(u) \dv{\mu(u)}{\mu_0(u)} \rho_0(u) \dd u,
    $$
provided that \(\dd \mu\), \(\dd \mu_0\) and \(f\) are nice enough (which they are since we're working
with Gaussians). This holds for all test functions \(f\), so it must hold pointwise:
$$ \dv{\mu(u)}{\mu_0(u)} = \frac{\rho(u)}{\rho_o(u)}.$$

Using this we recover the more familiar formulation of Bayes' formula:
$$\frac{\rho(u)}{\rho_o(u)} \propto \text{L}(u).$$

\subsubsection{Acceptance Probability for Metropolis-Hastings}
\label{sec:org4ceaaea}
A Markov process with transition probabilities \(t(y|x)\) has a stationary distribution \(\pi(x)\).
\begin{itemize}
\item The \uline{existence} of \(\pi(x)\) follows from \emph{detailed balance}:
$$\pi(x)t(y|x) = \pi(y)t(x|y).$$
Detailed balance is sufficient but not necessary for the existence of a stationary distribution.
\item \uline{Uniqueness} of \(\pi(x)\) follows from the Ergodicity of the Markov process. For a Markov
processto be Ergodic it has to:
\begin{itemize}
\item not return to the same state in a fixed interval
\item reach every state from every other state in finite time
\end{itemize}
\end{itemize}

The Metropolis-Hastings algorithm constructs transition probabilities \(t(y|x)\) such that the
two conditions above are satisfied and that \(\pi(x) = P(x)\), where \(P(x)\) is the distribution
we want to sample from.

Rewrite detailed balance as
$$\frac{t(y|x)}{t(x|y)} = \frac{P(y)}{P(x)}.$$
Split up the transition probability into proposal \(g(y|x)\) and acceptance \(a(y,x)\). Then detailed
balance requires
$$\frac{a(y,x)}{a(x,y)} = \frac{P(y)g(x|y)}{P(x)g(y|x)}.$$
Choose
$$a(y,x) = \min\left\{1, \frac{P(y)g(x|y)}{P(x)g(y|x)}\right\}$$
to ensure that detailed balance is always satisfied. Choose \(g(y|x)\) such that ergodicity
is fulfilled.

If the proposal is symmetric (\(g(y|x) = g(x|y)\)), then the acceptance takes the simpler form
\begin{equation}
\label{eqn:acceptance_simple}
a(y,x) = \min\left\{1, \frac{P(y)}{P(x)}\right\}.
\end{equation}

Since the target distribution \(P(x)\) only appears as a ratio, normalizing factors can be ignored.

\subsubsection{Potential for Bayes'-MCMC when sampling from analytic distributions}
\label{sec:orgc57b2c5}
How can we use formulations of Metropolis-Hastings-MCMC algorithms designed to sample from
posteriors when want to sample from probability distribution with an easy analytical expression?

Algorithms for sampling from a posterior sample from
$$\rho(u) \propto \rho_0(u) \exp(-\Phi(u)),$$
where \(\rho_0\) is the prior and \(\exp(-\Phi(u))\) is the likelihood. Normally, we have an
efficient way to compute the likelihood.

When we have an efficient way to compute the posterior \(\rho\) and we want to sample from it,
the potential to do that is:
$$\Phi(u) = \ln(\rho_0(u)) - \ln(\rho(u)),$$
where an additive constant from the normalization was omitted since only potential differences
are relevant.

When working with a Gaussian prior \(\N{0}{\C}\), the potential takes the form
$$\Phi(u) = -\ln{\rho(u)} - \frac{1}{2} \norm{\C^{-1/2}u}^2.$$

When inserting this into the acceptance probability for the standard random walk MCMC given
in formula (1.2) in \cite{cotter_mcmc_2013}, the two Gaussian-expressions cancel, as do the
logarithm and the exponentiation, leaving the simple acceptance described in \ref{eqn:acceptance_simple}.

This cancellation does not happen when using the pCN-Acceptance probablity. This could
explain the poorer performance of pCN when directly sampling a probablity distribution.

\subsubsection{Acceptance Probabilities for different MCMC Proposers}
\label{sec:org4119f49}
Start from Bayes' formula and rewrite the likelyhood \(\text{L}(u)\) as \(\exp(-\Phi(u))\) for
a positive scalar function \(\Phi\) called the potential:
$$\frac{\rho(u)}{\rho_o(u)} \propto \exp(\Phi(u)).$$
Assuming our prior to be a Gaussian (\(\mu_0 \sim \N{0}{\C}\)).

Then $$\rho(u) \propto \exp\left( -\Phi(u) + \frac{1}{2} \norm{C^{-1/2}u}^2 \right),$$
since \(u^T C^{-1} u = (C^{-1/2} u)^T(C^{-1/2} u) = \langle C^{-1/2}u, C^{-1/2}u \rangle = \norm{C^{-1/2} u}^2\),
where in the first equality we used \(C\) being symmetric.

This is formula (1.2) in \cite{cotter_mcmc_2013} and is used in the acceptance probability for
the standard random walk (see also \hyperref[sec:org4ceaaea]{Acceptance Probability for Metropolis-Hastings})

\(\C^{-1/2}u\) makes problems in infinite dimensions.

Todo: Why exactly is the second term (from the prior) cancelled when doing pCN?
\subsubsection{Different formulations of multivariate Gaussians}
\label{sec:org2782a1a}
Is an RV \(\xi \sim \N{0}{C}\) distributed the same as \(C^{1/2}\xi_0\), with \(\xi_0 \sim \N{0}{\I}\)?

From wikipedia: Affine transformation \(Y = c + BX\) for \(X \sim \N{\mu}{\Sigma}\) is also a Gaussian
\(Y \sim \N{c + B\mu}{B\Sigma B^T}\). In our case \(X \sim \N{0}{\I}\), so \(Y \sim \N{0}{C^{1/2}\I {C^{1/2}}^{T}} = \N{0}{C}\),
since the covariance matrix is positive definite, which means it's square root is also positive definite
and thus symmetric.

On second thought, it also follows straight from the definition:
$$
      \mathbf{X} \sim \N{\mu}{\Sigma}
      \Leftrightarrow
      \exists \mu \in \R^k, A \in \R^{k \cross l}
        \text{ s.t. }
        \mathbf{X} = \mu + A\mathbf{Z}
        \text{ with } \mathbf{Z}_n \sim \N{0}{1} \text{ i.i.d}
    $$
where \(\Sigma = AA^T\).
\subsubsection{Autocorrelation of non-centered distributions}
\label{sec:orgca542e8}

A common definition of the autocorrelation function of a series \(\{X_t\}\) is (cite something here?)

\begin{equation}
\label{eqn:def_ac}
R(\tau) = \E{X_t X_{t+\tau}^*},
\end{equation}

which can be normalized by \(\tilde{R}(\tau) = R(\tau) / R(0)\) \footnote{Since we're only working with real numbers, the complex conjugate in the definition will
be dropped from now on.}.

For calculating \(R\) of a finite series \(\{X_t\}_{t=1}^{T}\), the series can either be
zero-padded or the summation limits adjusted accordingly:

\begin{equation}
R(\tau) = \sum_{t=1}^{T-\tau} X_t X_{t+\tau} \text{  for } \tau < T
\end{equation}

This seems to be the definition that is used in the function \href{https://numpy.org/doc/1.18/reference/generated/numpy.correlate.html}{\texttt{np.correlate}}:
\texttt{c\_\{av\}[k] = sum\_n a[n+k] * conj(v[n])} (where we get autocorrelation for \texttt{a=v=x}).

This gives the expected result for uniformly random noise in \([-1, 1]\). However, when shifting
the same distribution by a constant factor to get uniformly random noise in \([0, 2]\), the
autocorrelation decays approximately linearly: \ref{fig:ac_uni}.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/ac_theory.png}
\caption{\label{fig:ac_uni}
Autocorrelation function of the same signal \(\{X_t \sim \mathcal{U}([0,2])\}\), once computed with \texttt{np.correlate} on the original series (uncentered), and once for \(\{X_t - 1\}\) (centered).}
\end{figure}

To see why this happens, split up the signal into its mean plus a mean-zero pertubation:
\(X_t = \overline{X} + \tilde{X}_t\), where \(\overline{X} = \E{X}\) and \(\E{\tilde{X}} = 0\).
The normalized autocorrelation is then:

\begin{align}
\tilde{R}(\tau) =& \frac{\sum_{t=1}^{T-\tau} X_t X_{t+\tau}}
                        {\sum_{t=1}^{T} X_t^2} \\
                =& \frac{\sum_{t=1}^{T-\tau} (\overline{X} + \tilde{X}_t) (\overline{X} + \tilde{X}_{t+\tau})}
                        {\sum_{t=1}^{T} (\overline{X} + \tilde{X}_t)^2} \\
                =& \frac{(T-\tau) \overline{X}^2 + \overline{X} \sum_{t=1}^{T-\tau} (\tilde{X}_t + \tilde{X}_{t+\tau}) + \sum_{t=1}^{T-\tau}\tilde{X}_t \tilde{X}_{t+\tau}}
                        {T \overline{X}^2 + 2 \overline{X} \sum_{t=1}^T \tilde{X}_t + \sum_{t=1}^T \tilde{X}_t^2} \\
                =& \frac{(T-\tau) \overline{X}^2}
                        {T(\overline{X}^2 + \text{var}(X))},
\end{align}

where the last equality holds because
\begin{itemize}
\item \(\lvert\sum_{t=1}^{T-\tau} (\tilde{X}_t + \tilde{X}_{t+\tau})\rvert < \epsilon\) and \(\lvert\sum_{t=1}^T \tilde{X}_t \rvert < \epsilon\)
when \(T >> \tau\) by the weak law of large numbers
\item \(\sum_{t=1}^{T-\tau}\tilde{X}_t \tilde{X}_{t+\tau} = R(\tau) = 0\) for \(\tau \neq 0\) and X "uncorrelated"
\item \(\sum_{t=1}^T \tilde{X}_t^2 = T \cdot \text{var}(\tilde{X}) = T \cdot\text{var}(X)\)
\end{itemize}

This is a linear function in \(\tau\), which is what we see in the plots (plus quite some noise).

For \(\overline{X} >> \text{var}(X)\), we get \(\tilde{R}(\tau) = 1 - \tau / T\), which explains nicely
why in the "uncentered" autocorrelation always linearly decays to 0, independently of the signal length \(T\).

Considering these points, the python-function that computes the autocorrelation we're actually interested
in \footnote{The function I'm describing here is called auto-covariance function \(K_{XX} = \E{(X_t - \mu) (X_{t+\tau} - \mu)^*}\).} looks like this:

\begin{minted}[]{python}
def autocorr(x):
    x_centered = x - np.mean(x)
    result = np.correlate(x_centered, x_centered, mode='full')
    # numpy computes the correlation from -\infty to +\infty
    result = result[-len(x):]
    # normalize the result
    return result / result[0]
\end{minted}

Much of this hassle could be avoided when the expectation value in the definition of the autocorrelation
\ref{eqn:def_ac} would be computed correctly (not just "a posteriori" in the normalizing step with
a much too large factor for bigger values of \(\tau\)). However, this is not possible while still taking
advantage of the huge speedup of doing the convolution operation in Fourier space.

\section{Framework/Package Structure}
\label{sec:org48b88f5}
The framework is designed to support an easy use case:
\begin{minted}[]{python}
proposer = StandardRWProposer(beta=0.25, dims=1)
accepter = AnalyticAccepter(my_distribution)
rng = np.random.default_rng(42)
sampler = MCMCSampler(rw_proposer, accepter, rng)

samples = sampler.run(x_0=0, n_samples=1000)
\end{minted}

There is only one source of randomness, shared among all classes and supplied by the user.
This facilitates reproducability.

Tests are done with \texttt{pytest}.
\subsection{Distributions}
\label{sec:org3d42016}
A class for implementing probability distributions.
\begin{minted}[]{python}
class DistributionBase(ABC):
    @abstractmethod
    def sample(self, rng):
        """Return a point sampled from this distribution"""
        ...
\end{minted}

The most important realisation is the \texttt{GaussianDistribution}, used
in the proposers.

\begin{minted}[]{python}
class GaussianDistribution(DistributionBase):
    def __init__(self, mean=0, covariance=1):
        ...

    def sample(self, rng):
        ...

    def apply_covariance(self, x):
        ...

    def apply_sqrt_covariance(self, x):
        ...

    def apply_precision(self, x):
        ...

    def apply_sqrt_precision(self, x):
        ...
\end{minted}

The design of this class is based on the implementation in \href{http://muq.mit.edu/master-muq2-docs/CrankNicolson\_8py\_source.html}{muq2}. The \texttt{precision} / \texttt{sqrt\_precision}
is implemented through a Cholesky decomposition, computed in the constructor. This makes
applying them pretty fast (\(\mathcal{O}(n^2)\)).

At the moment the there is one class for both scalar and multivariate Gaussians. This
introduces some overhead as it has to work with both \texttt{float} and \texttt{np.array}. Maybe two
seperate classes would be better.

Also, maybe there is a need to implement a Gaussian using the Karhunen-Loéve-Expansion?
\subsection{Potentials}
\label{sec:orgfa2662c}
A class for implementing the potential resulting from rewriting the likelihood as
$$\text{L}(u) = \exp(- \Phi(u)).$$

\begin{minted}[]{python}
class PotentialBase(ABC):
"""
    Potential used to express the likelihood;
    d mu(u; y) / d mu_0(u) \propto L(u; y)
    Write L(u; y) as exp(-potential(u; y))
    """
    @abstractmethod
    def __call__(self, u):
        ...

    @abstractmethod
    def exp_minus_potential(self, u):
        ...
\end{minted}

The two functions return \(\Phi(u)\) and \(\exp(-\Phi(u))\) respectively. Depending on the
concrete potential, one or the other is easier to compute.

Potentials are used in the accepters to decide the relative weight of different configurations.
They use the \texttt{\_\_call\_\_}-method to do that. Especially for high-dimensional error-terms, the
value of the pdf of the error term can become very small, so it is important to implement this
computing the logpdf directly instead of manually exponentiating and running into issues with
floating point number limitations.

\subsubsection{AnalyticPotential}
\label{sec:orga91c4d9}

This potential is used when sampling from an analytically computable probability distribution,
i.e. a known posterior. In this case
$$\exp(-\Phi(u)) = \frac{\rho(u)}{\rho_0(u)},$$
see \url{theory.org}
\subsubsection{EvolutionPotential}
\label{sec:org172b629}

This potential results when sampling from the model-equation
$$y = \G{u} + \eta,$$
with \(\eta \sim \rho\). The resulting potential can be computed as
$$\exp(-\Phi(u)) = \rho(y - \G{u}).$$

\subsection{Proposers}
\label{sec:orge83ed87}

Propose a new state \(v\) based on the current one \(u\).

\begin{minted}[]{python}
class ProposerBase(ABC):
    @abstractmethod
    def __call__(self, u, rng):
        ...
\end{minted}

\subsubsection{StandardRWProposer}
\label{sec:orgd6bafac}

Propose a new state as
$$v = u + \sqrt{2\delta} \xi,$$
with either \(\xi \sim \N{0}{\I}\) or \(\xi \sim \N{0}{\C}\) (see section 4.2 in \cite{cotter_mcmc_2013}).

This leads to a well-defined algorithm in finite dimensions.
This is not the case when working on functions (as described in section 6.3 in \cite{cotter_mcmc_2013})

\subsubsection{pCNProposer}
\label{sec:orgaf2702c}

Propose a new state as
$$v = \sqrt{1-\beta^2} u + \beta \xi,$$
with \(\xi \sim \N{0}{\C}\) and \(\beta = \frac{8\delta}{(2+\delta)^2} \in [0,1]\)
(see formula (4.8) in \cite{cotter_mcmc_2013}).

This approach leads to an improved algorithm (quicker decorrelation in finite dimensions,
nicer properties for infinite dimensions)(see sections 6.2 + 6.3 in \cite{cotter_mcmc_2013}).

The wikipedia-article on the Cholesky-factorization mentions the use-case of obtaining a
correlated sample from an uncorrelated one by the Cholesky-factor. This is not implemented here.
\subsection{Accepters}
\label{sec:org1d272e7}

Given a current state \(u\) and a proposed state \(v\), decide if the new state is accepted or rejected.

For sampling from a distribution \(P(x)\), the acceptance probability for a symmetric proposal is
\(a = \text{min}\{1, \frac{P(v)}{P(u)}\}\)
(see \url{theory.org})

\begin{minted}[]{python}
class ProbabilisticAccepter(AccepterBase):
    def __call__(self, u, v, rng):
        """Return True if v is accepted"""
        a = self.accept_probability(u, v)
        return a > rng.random()

    @abstractmethod
    def accept_probability(self, u, v):
        ...
\end{minted}

\subsubsection{AnalyticAccepter}
\label{sec:orgbc5b2ee}

Used when there is an analytic expression of the desired distribution.

\begin{minted}[]{python}
class AnalyticAccepter(ProbabilisticAccepter):
    def accept_probability(self, u, v):
        return self.rho(v) / self.rho(u)
\end{minted}

\subsubsection{StandardRWAccepter}
\label{sec:org5b09c59}

Based on formula (1.2) in \cite{cotter_mcmc_2013}:
$$a = \text{min}\{1, \exp(I(u) - I(v))\},$$ with
$$I(u) = \Phi(u) + \frac{1}{2}\norm{\C^{-1/2}u}^2$$.

See also \url{theory.org}.

\subsubsection{pCNAccepter}
\label{sec:org2607178}

Works together with the \hyperref[sec:orgaf2702c]{pCNProposer} to achieve the simpler expression for the acceptance
$$a = \text{min}\{1, \exp(\Phi(u) - \Phi(v))\}.$$

\subsubsection{CountedAccepter}
\label{sec:org637ba9f}

Stores and forwards calls to an "actual" accepter. Counts calls and accepts and is used for
calculating the acceptance ratio.

\subsection{Sampler}
\label{sec:org6ab6f7d}

The structure of the sampler is quite simple, since it can rely heavily on the functionality
provided by the Proposers and Accepters.

\begin{minted}[]{python}
class MCMCSampler:
    def __init__(self, proposal, acceptance, rng):
        ...

    def run(self, u_0, n_samples, burn_in=1000, sample_interval=200):
        ...

    def _step(self, u, rng):
        ...
\end{minted}

\section{Results}
\label{sec:org00401c2}
\subsection{Analytic sampling from a bimodal Gaussian}
\label{sec:org4623b6c}
\subsubsection{Setup}
\label{sec:org1610f60}

Attempting to recreate the "Computational Illustration" from \cite{cotter_mcmc_2013}. They use,
among other algorithms, pCN to sample from a 1-D bimodal Gaussian
$$\rho \propto (\N{3}{1} + \N{-3}{1}) \mathds{1}_{[-10,10]}.$$
Since the density estimation framework for a known distribution is not quite clear to me from
the paper, I don't expect to perfectly replicate their results.

They use a formulation of the prior based on the Karhunen-Loéve Expansion that doesn't make
sense to me in the 1-D setting (how do I sum infinite eigenfunctions of a scalar?).

The potential for density estimation described in section is also not clear to me (maybe for
a similar reason? What is \(u\) in the density estimate case?).

I ended up using a normal \(\N{0}{1}\) as a prior and the potential described \hyperref[sec:orgc57b2c5]{before}, and
compared the following samplers:
\begin{itemize}
\item (1) \href{code.org}{\texttt{StandardRWProposer}} (\(\delta=0.25\)) + \href{code.org}{\texttt{AnalyticAccepter}}
\item (2) \href{code.org}{\texttt{StandardRWProposer}} (\(\delta=0.25\)) + \href{code.org}{\texttt{StandardRWAccepter}}
\item (3) \href{code.org}{\texttt{pCNProposer}} (\(\beta=0.25\)) + \href{code.org}{\texttt{pCNAccepter}}
\end{itemize}

The code is in \href{scripts/analytic.py}{\texttt{analytic.py}}.

\subsubsection{Result}
\label{sec:org8ea46fc}

All three samplers are able to reproduce the target density \ref{fig:hist_bimodal}

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/bimodal_density_combined.png}
\caption{\label{fig:hist_bimodal}
Burn-in: 1000, sample-interval: 200, samples: 500}
\end{figure}

The autocorrelation decays for all samplers: \ref{fig:ac_bimodal}. However, the pCN doens't
do nearly as well as expected. This could be the consequence of the awkward
formulation of the potential or a bad prior.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/analytic_standard_rw_pCN_50_5000.png}
\caption{\label{fig:ac_bimodal}
AC of bimodal distribution. pCN takes forever to decorrelate}
\end{figure}

\subsection{Bayesian inverse problem for \(\G{u} = \langle g,u \rangle\)}
\label{sec:orged9d588}
For \(\G{u} = \langle g,u \rangle\) the resulting posterior under a Gaussian prior
is again a Gaussian. The model equation is
$$y = \G{u} + \eta$$
with:
\begin{itemize}
\item \(y \in \R\)
\item \(u \in \R^n\)
\item \(\eta \sim \N{0}{\gamma^2}\) for \(\gamma \in \R\)
\end{itemize}

A concrete realization with scalar \(u\):
\begin{itemize}
\item \(u = 2\)
\item \(g = 3\)
\item \(\gamma = 0.5\)
\item \(y=6.172\)
\item prior \(\N{0}{\Sigma_0=1}\)
\end{itemize}
leads to a posterior with mean
\(\mu = \frac{(\Sigma_0g)y}{\gamma^2 + \langle g, \Sigma_0g \rangle} \approx 2\),
which is what we see when we plot the result \ref{fig:stuart_21_density}.
The pCN-Sampler with \(\beta = 0.25\) had an acceptance rate of 0.567.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/stuart_example_21_n=1_N=5000.png}
\caption{\label{fig:stuart_21_density}
\(N=5000, \mu \approx 2\)}
\end{figure}

For \(n>2\), the resulting posterior can not be plotted anymore. However, it is still Gaussian
with given mean \& covariance. Can just compare the analytical values to the sample values.
Verify that the error decays like \(\frac{1}{\sqrt{N}}\).
\subsection{Bayesian inverse problem for \(\G{u} = g (u + \beta u^3)\)}
\label{sec:org4719d11}
Since the observation operator is not linear anymore, the resulting posterior is not
Gaussian in general. However, since the dimension of the input \(u\) is 1, it can
still be plotted.

The concrete realization with:
\begin{itemize}
\item \(g = [3, 1]\)
\item \(u = 0.5\)
\item \(\beta = 0\)
\item \(y= [1.672, 0.91]\)
\item \(\gamma = 0.5\)
\item \(\eta \sim \N{0}{\gamma^2 I}\)
\item prior \(\N{0}{\Sigma_0=1}\)
\end{itemize}
however leads to a Gaussian thanks to \(\beta = 0\). The mean is
\(\mu = \frac{\langle g,y \rangle}{\gamma^2 + |g|^2} \approx 0.58\). Plot: \ref{fig:stuart_22_density}

The pCN-Sampler with \(\beta = 0.25\) (different beta) had an acceptance rate of 0.576.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/stuart_example_22_q=2_N=5000.png}
\caption{\label{fig:stuart_22_density}
\(N=5000, \mu \approx 0.58\)}
\end{figure}

For \(\beta \neq 0\), the resulting posterior is not a Gaussian. Still \(n=1\), so it can be
plotted. Just numerically normalize the analytical expression of the posterior?

\subsection{Lorenz96 model}
\label{sec:org7a6206b}
\subsubsection{Model}
\label{sec:org970d4d8}
\paragraph{Based on:}
\label{sec:org2100efd}

Properly cite this!


Lorenz, E. N. (1996). Predictability—A problem partly solved. In Reprinted in T. N. Palmer \& R. Hagedorn (Eds.), Proceedings Seminar on
Predictability, Predictability of Weather and Climate, Cambridge UP (2006) (Vol. 1, pp. 1–18). Reading, Berkshire, UK: ECMWF.

\paragraph{Equation}
\label{sec:orgaeecb98}

A system of ODEs, representing the coupling between slow variables \(X\) and fast, subgrid
variables \(Y\). The system is used in \cite{schneider_earth_2017} to illustrate different
algorithms for earth system modelling.

\begin{equation}
\label{eqn:lorenz_X}
  \dv{X_k}{t} =                 - X_{k-1}(X_{k-2} - X_{k+1}) - X_k + F - hc \bar{Y}_k
\end{equation}

\begin{equation}
\label{eqn:lorenz_Y}
  \frac{1}{c} \dv{Y_{j,k}}{t} = -bY_{j+1,k}(Y_{j+2,k} - Y_{j-1, k}) - Y_{j,k} + \frac{h}{J}X_k
\end{equation}

\begin{itemize}
\item \(X = [X_0, ..., X_{K-1}] \in \R^K\)
\item \(Y = [Y_{j, 0} | ... | Y_{j, K-1}] \in \R^{J \cross K}\) \\
\(Y_{j,k} = [Y_{0,k}, ..., Y_{J-1,k}] \in  \R^J\)
\item \(\bar{Y}_k = \frac{1}{J}\sum_j Y_{j,k}\)
\item periodic: \(X_K = X_0\), \(Y_{J,k} = Y_{0,k}\)
\item Parameters \(\Theta = [F, h, c, b]\)
\item \(h\): coupling strength
\item \(c\): relative damping
\item \(F\): external forcing of the slow variables (large scale forcing)
\item \(b\): scale of non-linear interaction of fast variables
\item \(t = 1 \Leftrightarrow 1\) day (simulation duration is given in days)
\end{itemize}

\subparagraph{\(b\) or \(J\)?}
\label{sec:orgac993bc}
In the original paper, the equations are given in a different form, namely all
explicit occurences of \(J\) above (in the fast-slow interaction) are replaced by
\(b\). Since in both concrete realizations (1996 \& 2017) are identical and conviniently
have \(b=J=10\), the difference doesn't lead to different results for that setup.

\subparagraph{"Looking ahead" vs. "Looking back"}
\label{sec:org5435b39}
Comparing nonlinearity terms
$$-X_{k-1}(X_{k-2} - X_{k+1})$$
$$-bY_{j+1,k}(Y_{j+2,k} - Y_{j-1, k})$$
for a given \(Y_{k}\), does the "direction" of the \(Z_{k\pm 1}Z_{k\pm 2}\) (\(Z=X,Y\)) matter?

I don't think so, since the interaction with the other variable is only via point-value
and average, and the nonlinearity is periodic.

A bit more formally:
The PDE is invariant under "reversing" of the numbering:
\(Y_{j,k} \rightarrow Y_{J-j,k}\) which is the same as switching \(+ \leftrightarrow -\) in
the only "asymmetric" term.

Addendum 2 days later: Need to define more clearly what it means for the direction to
\uline{matter}. In the original paper on page 12, it is described how "active areas [..] propagate
slowly eastward", while "convective activity tends to propagate westward within the active
areas" (rephrased from paper). The paper also explicitly mentions the signs of the subscripts
in that context. So some characteristics of the solution are definitely affected.
What about the stuff we care about (statistical properties, chaotic behaviour)?


\paragraph{Properties}
\label{sec:org208b923}

For \(K=36\), \(J=10\) and \(\Theta = [F, h, c, b] = [10, 1, 10, 10]\) there is chaotic behaviour.

\subparagraph{Energy}
\label{sec:orgee970ba}

The nonlinearities conserve the energies within a subsystem:
\begin{itemize}
\item \(E_X = \sum_k X_k^2\)

\(\frac{1}{2} \dv{(\sum_k X_k^2)}{t} =
         \sum_k X_k \dv{X_k}{t} =
         -\sum_k (X_k X_{k-1} X_{k-2} - X_{k-1} X_{k} X_{k+1}) =
         0\),

where the last equality follows from telescoping + periodicity
\item \(E_{Y_k} = \sum_j Y_{j,k}^2\)

which follows analogously to the \(X\) -case
\end{itemize}

The interaction between fast and slow variables conserves the total energy:
\begin{itemize}
\item \(E_{T} = \sum_k (X_k^2 + \sum_j Y_{j,k}^2)\)

\(\frac{1}{2} \dv{E_{T}}{t} =
         \sum_k X_k \dv{X_k}{t} + \sum_j Y_{j,k} \dv{Y_j,k}{t} =
         \sum_k X_k (- \frac{hc}{J} \sum_j Y_{j,k}) + \sum_j Y_{j,k} (\frac{hc}{J} X_k) =
         \sum_k - \frac{hc}{J} X_k (\sum_j Y_{j,k} + \frac{hc}{J} X_k (\sum_j Y_{j,k})) = 
         0\)
\end{itemize}

In the statistical steady state, the external forcing \(F\) (as long as its positive) balances
the dampling of the linear terms.

\subparagraph{Averaged quantities}
\label{sec:org7717376}

$$\expval{\phi} = \frac{1}{T} \int_{t_0}^{t_0 + T} \phi(t) \dd{t}$$ (or a sum over discrete values)

Long-term time-average in the statistical steady state: \(\expval{\cdot}_{\infty}\)

\begin{itemize}
\item \begin{equation}
\label{eqn:equilibrium_X}
   \expval{X_k^2}_\infty = F \expval{X_k}_{\infty} - hc \expval{X_k\bar{Y_k}}_\infty \forall k
\end{equation}
(multiply \(X\) -equation by \(X\), all \(X_k\) s are statistically equivalent, \(\dv{\expval{X}}{t} = 0\) in steady state)
\item \begin{equation}
\label{eqn:equilibrium_Y}
  \expval{\bar{Y_k^2}}_{\infty} = \frac{h}{J} \expval{X_k \bar{Y_k}}_{\infty} \forall k
\end{equation}
\end{itemize}

\subparagraph{(Quasi) Ergodicity}
\label{sec:org5821315}

Whether chaotic regions of the phase space of a system are ergodic seems not be an easy question
to answer (citation needed probably) \footnote{Are there any inaccessible regions in phase space
for the Lorenz system? I can't think of any. However, there seem to be "traps" that take the
system out of it's chaotic behaviour (\(X_i = c\), \(Y_i=a\)). These destroy ergodicity.
Are they somehow "measure 0" or something?} Are there any inaccessible regions in phase space
for the Lorenz system? I can't think of any. However, there seem to be "traps" that take the
system out of it's chaotic behaviour (\(X_i = c\), \(Y_i=a\)). These somehow destroy ergodicity.
Are they somehow "measure 0" or something?)/. However, for the purposes of this section (which deals with
finite time anyway), it is enough to assert that

for the Lorenz system, for sufficiently long times, the time-average converges to the
"space-average" over phase-space:

\begin{equation}
\label{eqn:lorenz_ergodicity}
   \expval{f}_{\infty} = \lim_{T \to \infty} \int_0^T f(Z(t)) \dd{t} = \int_{\R^{K(J+1)}} f(x) \rho(x) \dd{x}
\end{equation}

where \(Z(t)\) is a phase space trajectory of the system and \(\rho(x)\) is the probaility of the
system in the statistical steady state to be in state \(x\).

One sufficiently long simulation of the system gives information about all accessible \footnote{Here a more precise definition of ergodicity of the system would help out. What I mean
is "all sensible initial conditions".} initial conditions.
As a consequence, as long as the integration time of the system is "long enough", the chosen initial
condition is meaningless and can even vary without changing the behaviour of the observation operator.

\subsubsection{Model implementation}
\label{sec:org2291510}

Implementing the model in python and using a locally 5-th order RK solver yields the following
results (inital conditions are just uniformly random numbers in \([0,1)\) since they don't matter
for the long-term evolution of the chaotic system):

\paragraph{Reproducting the results of the original paper}
\label{sec:org0825668}
Running the setup with \(K=36, J=10, (F, h, c, b) = (10, 1, 10, 10)\) gives the following states
\ref{fig:lorenz96_combined},
which qualitatively agree with the results from Lorenz.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/lorenz96_combined.png}
\caption{\label{fig:lorenz96_combined}
System around \(T=20\)}
\end{figure}

The decay of the linear term and the forcing of the slow variables balance out after reaching the
steady state, however there is a much bigger fluctuation in the energy than expected \ref{fig:lorenz_energy}.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/lorenz96_energies.png}
\caption{\label{fig:lorenz_energy}
Energies in the system. \(E_X >> E_{Y_k} > 0\)}
\end{figure}

\paragraph{Equilibrium averages}
\label{sec:org9564d8b}
Analysis suggests certain long-term averages to be equal in the equilibrium.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/equilibrium_error_n=10.png}
\caption{\label{fig:lorenz_rmse}
RMSE for long-term averages \ref{eqn:equilibrium_X} and \ref{eqn:equilibrium_Y}. Averaged over 10 runs}
\end{figure}

\subsubsection{MCMC}
\label{sec:org59f42c2}
General point: The \texttt{RK45} method uses a predictor/corrector step and thus does non-uniform timesteps.
However, in the following I compute time-averages with a simple \texttt{np.mean}, ignoring the different
length of timesteps. It would be not impossible to write my own \texttt{time\_average(y, t)}-function that
takes the non-uniform timesteps into account. However I'm not sure how necessary this is, considering
a forward-integration takes \(\mathcal(2000)\) timesteps, so I suspect that differences are washed out
a bit?

\paragraph{Setup}
\label{sec:orgee1ec75}
Denote the Lorenz-96 system \ref{eqn:lorenz_X}, \ref{eqn:lorenz_Y} with parameters \(\tilde{u} = [F, h, c, b]\) as
\(\mathcal{M}[\tilde{u}]\). It acts on the initial condition \(z_0 = [X_0, Y_0] \in \R^{K(J+1)}\) to evolve
the system for \(N_t\) timesteps and generate the phase space trajectory
\(Z = \left[ \smash{{}^{X_1}_{Y_1}} | \cdots | \smash{{}^{X_{N_t}}_{Y_{N_t}}}  \right] \in
   \R^{K(J+1) \cross N_t}\):
$$Z = \mathcal{M}[\tilde{u}] z_0$$

Define the "moment function" \(f(z): \R^{K(J+1)} \to \R^{5K}\)

\begin{align}
  f(z) &=
  \begin{bmatrix}
    X \\
    \bar{Y} \\
    X^2 \\
    X \bar{Y} \\
    \overline{Y^2}
  \end{bmatrix}
\end{align}

The MCMC-Algorithm then samples based on:

$$\expval{f}_\infty = \expval{f}_T(u) + \eta$$
with:
\begin{itemize}
\item \(\expval{f}_\infty \approx \expval{f}_{T_r}\) with \(T_r >> T\) over a simulation \(\mathcal{M}[u^*] z_0\)
\item \(\expval{f}_T(u)\) the time average over a simulation \(\mathcal{M}[u_p + u] z_0\)
\item Due to the ergodic properties of \(\mathcal{M}\) \ref{sec:org5821315} , it doesn't really matter what \(z_0\) is
\item The parameter vector comes in many different variations:
\begin{itemize}
\item \(u^* \in \R^4_{\geq 0}\): true underlying parameters, used to compute the "data"
\item \(u_p \in \R^4_{\geq 0}\): mean of the prior
\item \(u \in \R^4\): pertubations to the prior mean, the actual input to the observation operator
\end{itemize}
\item \(\eta \sim \N{0}{\Sigma}\), where \(\Sigma = r^2 [\text{var}(f)_{T_r}]\),
where \(r \in \R\) is the "noise level"
\end{itemize}

\begin{enumerate}
\item The parameter vector \(u\)
\label{sec:org13c278e}

The theoretical background assumes the prior to be a centered Gaussian (\(\mu = 0\)).
Specifically, it matters during the proposal step, where the step is taken either with
scaled sample from the prior or from a centered Gaussian with the covariance of the prior.
A compromise would be to just ignore a nonzero prior-mean in the proposal, however I'm not
sure if such a prior has other effects that invalidate the algorithm.

\item "Noise level"
\label{sec:org3bc14a9}

\(r\) is scaling of covariance matrix of noise term. This in turn is just step-width in proposal.

TODO: Verify by checking acceptance rate for different noise levels
\end{enumerate}

\subparagraph{Concrete parameters}
\label{sec:orgd9cad47}

The MCMC-Simulation was carried  out with the following parameters:

\begin{itemize}
\item \(K = 6, J = 4\)
\item Reference Simulation to get \(\expval{f}_\infty\) and \(\Sigma\):
\begin{itemize}
\item \(u^* = [F^*, h^*, c^*, b^*]= [10, 10, 1, 10]\)
\item \(T_r = 500\)
\end{itemize}
\item Noise \(\eta \sim \N{0}{\Sigma}\) with \(\Sigma = r^2 \text{diag}(\text{var}(f_{T_r})) \in \R^{5K \cross 5K}\)
\item Noise level \(r= 0.5\)
\item Prior \(\N{u_p}{\Sigma_0}\)
\begin{itemize}
\item \(u_p = [F_0, h_0, b_0] = [12, 8, 9]\)
\item \(\Sigma_0 = \text{diag}([10, 1, 10])\)
\item \(c\) was excluded from the sampling since it is very hard to estimate ("bad statistics")
\item The prior was chosen closer to the true value to make the job of the algorithm easier
\end{itemize}
\item Sampling with \emph{pCN} proposer and acccepter with \(\beta = 0.25\)
\begin{itemize}
\item Evaluating the observation operator with a model-simulation of \(T=20\)
\item Start sampling very close to true value: \(u_0 = [-1.9, 1.9, 0.9]\) so that \(u^* \approx u_p + u_0\)
\item This means we can use a short burn-in of 100
\item Sample \(N = 2500\) with a sample-interval of 2
\item The sample interval of 2 is very short, especially considering the long correlation time see below.
But 2 is also what they used in the ESM paper.
\end{itemize}
\end{itemize}

\paragraph{Result}
\label{sec:org47aa62b}

\subparagraph{Density plot for posterior}
\label{sec:orgec24b2c}

The resulting density plots show a improvement from the prior towards the true value \ref{fig:lorenz_densities}.
The estimation of the parameter \(F\) seems to be easier than \(b\), where the prior and the
posterior seem pretty much identical.

This slight improvement is however not unexpected, as the simulations I've done are much shorter than
the ones in \cite{schneider_earth_2017} (\(K, J) = (6,4)\) vs \((36, 10)\), \(T = 20\) vs 100, \(T_r = 500\) vs 46,416)

Should I do some more analysis here, like reporting sample means and covariances to compare
posterior/prior not just visually?

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/combined_K=6_J=4_T=20_r=0.5.png}
\caption{\label{fig:lorenz_densities}
Prior and Posteriors after a 5000 sample MCMC run}
\end{figure}

\subparagraph{ACF}
\label{sec:orgb82ef46}

The autocorrelation decays for all three variables. As expected from the accuracy of the posteriors,
the autocorrelation of \(F\) decays much faster than that of \(b\). This simulation was done with a
value of \(\beta=0.5\), which controls the "step size" of the proposer, and resulted in an acceptance
rate of around \(0.6\). The value for \(\beta\) can now be tuned in such a way to get the fastest decay
of the autocorrelation, which happens when the steps taken during sampling are big enough to
quickly decorrelate the chain, while not being so big that the accepter declines too many of the steps.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/lorenz_ac_avg_K=6_J=4_T=20_r=0.5.png}
\caption{\label{fig:lorenz_acF}
Autocorrelation of during the MCMC sampling. The functions are averaged over ten distinct parts of the chain}
\end{figure}
\subsection{Perturbed Riemann problem for Burgers' equation}
\label{sec:org6c7e318}
\subsubsection{Model}
\label{sec:org495abb2}
\paragraph{Burgers' Equation}
\label{sec:orga273dd1}

We consider the Burgers' equation

\begin{equation}
\label{eqn:burgers}
  w_t + \left( \frac{w^2}{2} \right)_x = 0
\end{equation}

in the domain \((x, t) \in [-1, 1] \cross [0,1]\).

\paragraph{Riemann Problem}
\label{sec:org8f41028}

The following family of initial conditions:

\begin{equation}
\label{eqn:perturbed_riemann}
  w(x, 0) =
  \begin{cases}
    1 + \delta_1 & \text{if } x < \sigma_0 \\
    \delta_2     & \text{if } x > \sigma_0    
  \end{cases}
\end{equation}

can be parametrized by the vector \(u = [\delta_1, \delta_2, \sigma_0] \in \R^3\).
As long as \(\norm{u} \ll 1\) we can expect \(w\) to behave very similarly to the
usual 1,0-Riemann problem (in particular the location of the shock at \(t=1\) will be
close to \(x=0.5\)).

\paragraph{Discretization}
\label{sec:org8d47fba}

Blabla
\subsubsection{MCMC}
\label{sec:orgb19173d}

\paragraph{Hyperparameter tuning}
\label{sec:org544f706}

To optimize hyperparameters, namely choose the step-size (pCN: \(\beta\), RW: \(\delta\)) such that for a given chain length
as many samples as possible can be used for estimation, the properties of the chain
should be well defined and computable.

The two important characteristics are the burn-in \(b\) and the decorrelation time \(\tau_0\).
Given these values for a chain of length \(N\), the number of usable samples \(M\) is

$$ M = \frac{N - b}{\tau_0} $$ 

\subparagraph{Burn-In \(b\)}
\label{sec:org774207a}

The most fruitful approach seems to be to visually inspect the evolution of the
parameter values and roughly decide when a steady-state is reached. This works nicely
as long as the step-size is not too small and we actually reach a steady state.

A more formal approach would require to actually define a criterion for the parameter
evolution in the chain that indicates when the steady state is reached. This is challenging,
especially when no knowledge of the underlying values (ground truth) is used, and when
the criterion should be valid for a wide range of step-sizes.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/burgers_chain_report.png}
\caption{\label{fig:burgers_burn-in}
Chain evolution during sampling with \(\beta=0.1\). Visually it seems the the steady-state is reached after around 1000 samples.}
\end{figure}

\subparagraph{Decorrelation time \(\tau_0\)}
\label{sec:orgeb1e28a}

After the burn-in is discarded from the original chain, the lag where the autocorrelation
function first equals 0 gives the number of samples after which they become decorrelated
\footnote{A different, more involved criterion would be to define the decorrelation time
as the integral over the autocorrelation function; \(\Theta\)}.

Since after burn-in the chain is in the statistical steady state, the autocorrelation
function is the same, regardless of which interval of the chain is investigated (this
is not the case before discarding the burn-in).

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/burgers_ac_report.png}
\caption{\label{fig:burgers_decorr_time}
Autocorrelation function during sampling with \(\beta=0.1\). For this chain, \(\tau_0 \approx 30\).}
\end{figure}

\subparagraph{Step size \(\beta\)}
\label{sec:orgdb01652}

Given a way to compute \(b\) and \(\tau_0\), the optimal \(\beta^*\) can be found as

$$\beta^* = \argmax M(\beta)$$

for a given chain length \(N\) (which is usually constrained by computational resources).

Generally, a bigger value of \(\beta\) will result in bigger steps proposed during the
MCMC steps. This results in a shorter burn-in at the expense of more declined steps during the
steady state, which results in longer decorrelation times.

Everything here also applies to \(\delta\), the step-size for the random-walk-MCMC algorithm.
\(\beta\) and \(\delta\) are related through \(\beta^2 = \frac{8 \delta}{(2 + \delta)^2}\).


\paragraph{Setup}
\label{sec:org7ef4fc0}

As usual, we sample based on the equation

$$y = \G{u} + \eta$$

with:
\begin{itemize}
\item \(y \in \R^q\): measurements obtained from a simulation of the ground truth
\item \(u \in \R^n\): vector parametrizing the pertubations to the Riemann initial conditions
\item \(\G{\cdot} :\R^n \to \R^q\): observation operator, measurements on the final state of the Riemann problem
\item \(\eta \sim \N{0}{\gamma^2 \I_q}\): assumed observational noise \footnote{I took the liberty of renaming variables to match more closely Stuart's notation
\cite{stuart_inverse_2010} and avoid collisions such as multiple occurences of \(\beta\).}
\end{itemize}

Stuart et. al. describe some cases in \cite{stuart_inverse_2010} (Theorem 2.17) for overdetermined 
problems (\(q > n\)), where the posterior converges to a Dirac measure when \(\gamma \to 0\).
This however only applies to linear invertible observational maps, which is definitely not the
case here. However for well-placed measurements we can definitely expect a sharp posterior.

\subparagraph{Observation operator \(\G{u}\)}
\label{sec:org2ba942c}

We use the FVM to evolve the Riemann intial conditions \ref{eqn:perturbed_riemann} \(w_u(x, 0)\)
until \(T=1\) and then measure the resulting state around certain measurement points:

\begin{equation}
L_i(w) = 10 \int_{x_i - 0.05}^{x_i + 0.05} w(x, 1) \dd x
\end{equation}

with \(1 \leq i \leq 5\) and \(x_1 = -0.5\), \(x_2= -0.25\), \(x_3 = 0.25\), \(x_4 = 0.5\), \(x_5 = 0.75\).

The observation operator is then:

$$yeah how do you write this out lol$$

\begin{enumerate}
\item Placement of measurements
\label{sec:org262661d}

The choice of the \(x_i\) s is crucial. If the shock is not contained in the measurement
interval around and \(x_i\), the Markov chain has no chance of determining the initial
shock location \(\sigma_0\) any more accurately than the spacing between measurements.

Conversely, if the measurement interval is large enough, a single measurement around the
shock gives enough information to determine all three parameters \(\delta_1, \delta_2, \sigma_0\)
simultaneously, provided the Markov chain "finds" to correct parameter configuration to place the
shock in the measurement interval.
\end{enumerate}

\subparagraph{Ground truth measurements \(y\)}
\label{sec:org407bcc4}

\(y\) is obtained by applying the observation operator to the ground truth \(u^*\).
$$u^* = [\delta_1^*, \delta_2^*, \sigma_0^*] = [0.025, -0.025, -0.02]$$

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/burgers_setup.png}
\caption{\label{fig:burgers_setup}
Setup for the MCMC experiment. The values for \(w\) at \(T=1\), once for the unperturbed Riemann problem, once for the ground truth of the simulation \(u^*\). The green rectangles are the measurement intvervals of the observation operator : \(\int_{x_i - 0.05}^{x_i + 0.05} w(x,1)\dd x\), \(x_i \in \{ -0.5, -0.25, 0.25, 0.5, 0.75 \}\).}
\end{figure}

\subparagraph{Noise}
\label{sec:org8bee14e}

\(\eta \sim \N{0}{\gamma^2 \I_5}\) with \(\gamma = 0.05\).

\subparagraph{Prior}
\label{sec:orgf7d5f8d}

\(\nu \sim \N{u_p}{\varphi^2 \I_3}\), with
\begin{itemize}
\item \(u_p = [1.5, 0.25, -0.5]\),
which corresponds to
\begin{itemize}
\item \(\delta_1^p = 1.5\)
\item \(\delta_2^p = 0.25\)
\item \(\sigma_0^p = -0.5\)
\end{itemize}
\item \(\varphi = 0.25\)
\end{itemize}

\paragraph{Result}
\label{sec:orgc200912}

\subparagraph{Investigating concrete values of \(\beta\)}
\label{sec:org051ecf1}

Three concrete values for \(\beta\) are investigated closer; \(\beta_1 = 0.01\), \(\beta_2 = 0.15\)
and \(\beta_3 = 0.5\). These values were chosen since they correspond to three significantly
different behaviours of the Markov chain.

The pCN-proposer computes prospective new states as

$$v = \sqrt{1-\beta^2} u + \beta \xi$$

with \(\xi \sim \N{0}{\Sigma_0}\), where \(\Sigma_0\) is the covariance of the prior. Ignoring the
scaling of the current state, a characteristic step-size can be said to be \(s = \beta \Sigma_0^{-\frac{1}{2}}\),
which in the case of \(\Sigma_0 = \gamma^2 \I_q\) takes the simpler form

\begin{equation}
\label{eqn:char_step}
  s = \beta \gamma
\end{equation}

It is interesting to compare this value to other numbers in the system.

Comparing \(s\) to the distance between the prior-mean and the ground truth (namely for \(\delta_{\text{1}}\),
for which this distance is largest) gives us a rough idea of the length of the burn-in we
can expect.

Conversely, the ratio betwenn \(s\) and the measurement interval can indicate how high the acceptance
ratio in the steady state might be.
The idea is that if the stepsize is much larger than the measurement interval, proposed states will
likely move the shock outside of the measurement interval and are thus often rejected. (This
relationship is admittedly not so simple, since a large change in \(\sigma_{\text{0}}\) can be compensated
by an adjustment in a \(\delta\))

\begin{enumerate}
\item \(\beta\) = 0.01
\label{sec:orgaa64443}

This very small value of beta gives a characteristic step size \(s = 0.0025\). Moving uniformly from
the prior-mean \(\delta_1^p = 1.5\) to the ground truth \(\delta_1^* = 0.025\) is expected to take
around 600 steps.

What we see in the actual chain evolution is quite different, the steps taken by are so small that
the chain gets stuck in a local minimum and places the shock in the wrong measurement interval, even
after 5000 steps. It can be argued that this is all part of the burn-in, and indeed also chains with
a larger \(\beta\) sometimes spend some iterations with the shock-value in the completely wrong location.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/burgers_pCN_n=5000_b=0.01_chain_report.png}
\caption{\label{fig:burgers_chain_01}
Evolution of the chain with \(\beta\) = 0.01. The small step size results in getting stuck in a local minimum, placing the around x=0.25 instead of x=0.5.}
\end{figure}

\item \(\beta\) = 0.5
\label{sec:orgb4aa968}

This large value of \(\beta\) results in stagnant behaviour in the steady state. Only very few moves
are accepted,  so the sampling interval has to be chosen very large to get adequately decorrelated
samples (the autocorrelation function doesn't reach 0 until well after 100 samples).
This is not too surprising when comparing the measurement interval of 0.1 around \(x=0.5\) with
the step-size \(s = 0.125\).

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/burgers_pCN_n=5000_b=0.5_chain_report.png}
\caption{\label{fig:burgers_chain_5}
Evolution of the chain with \(\beta\) = 0.5. After the burn-in, very few moves are accepted, resulting in a long decorrelation time (even longer than written on the figure).}
\end{figure}

\item \(\beta\) = 0.15
\label{sec:org2951c05}

With this value of \(\beta\) we get a "healthy" behaviour of the chain: the steps are large enough
to finish the burn-in in a reasonable time, while still being small enough to explore phase-space
around a favourable state. The characteristic step size \(s = 0.375\) reflects that fact.

However, the region which we explore in the steady-state is still quite large, result in
not very sharp posteriors. If sharper posteriors are needed, the value of \(\beta\) should
be decreased, while making sure the burn-in doesn't take too long.
An adaptive (decreasing whith chain length) value of \(\beta\) could help here.


\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/burgers_pCN_n=5000_b=0.15_chain_report.png}
\caption{\label{fig:burgers_chain_15}
Evolution of the chain with \(\beta\) = 0.15. After the burn-in, the phase space around the ground-truth is explored nicely. Interesting is the small "excursion" around step 4800.}
\end{figure}

\item Variable \(\delta\)
\label{sec:org850fc1e}

The idea to have a variable step-size (usually monotonically decreasing) to reap the benefits
of both worlds (short burn-in and quick decorrelation in the steady state) is frequently used
in optimization. There it is called \emph{simulated annealing}, based on an analogy to tempering metals.
The ground state (minimizing the free energy) of the system has favorable mechanical properties
and is reached by letting the metal cool slowly. This process is "simulated" by decreasing the
step-size of the Markov chain, which in a physical system corresponds to lowering the temperature.
This procedure can be very successful at finding global minima of challenging objective functions.

Here, we chose a linearly decreasing step-size during burn-in, which is kept constant after. The
results look promising and result in the best-performing chain.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/burgers_RW_n=5000_b=pwl_0.1_0.001_250_chain_report.png}
\caption{\label{fig:burgers_delta_pwl}
Evolution of the chain with a random walk proposal and a piecewise-linear \(\delta\), starting at \(\delta_s = 0.1\) and decreasing to \(\delta_e = 0.001\) during burn-in.}
\end{figure}
\end{enumerate}

\subparagraph{pCN vs ordinary random Walk}
\label{sec:orgfb970b8}

The pCN proposer generates new states as

$$v = \sqrt{1-\beta^2} u + \beta \xi,$$

while the ordinary random walk proposer does

$$x = u + \sqrt{2\delta}\xi$$

with \(\xi \sim \N{0}{\Sigma_0}\).

Equating the stepsize \(s\) gives \(\delta = 0.01125\) being equivalent to \(\beta = 0.15\).
The chain seems pretty comparable, but the burn-in is noticably shorter.
This can be attributed to the scaling of the current state \(\sqrt{1-\beta^2}\), which "pulls"
the proposed state towards the prior mean.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/burgers_RW_n=5000_delta=0.01125_chain_report.png}
\caption{\label{fig:burgers_delta_0}
Evolution of the chain with a random walk proposal and \(\delta = 0.01125\)}
\end{figure}

\subparagraph{Posterior estimates}
\label{sec:org829546d}

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/burgers_pCN_n=5000_b=0.15_densities_report.png}
\caption{\label{fig:burgers_densities_15}
Posterior densities, taken from the pCN-chain shown above with \(\beta = 0.15\), burn-in 500 and sampling interval 25.}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/burgers_posterior_RW_const.png}
\caption{\label{fig:burgers_densities_delta_001125}
Posterior densities, taken from the RW-chain shown above with \(\delta = 0.01125\), burn-in 500 and sampling interval 25.}
\end{figure}


\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./figures/burgers_posterior_pwl.png}
\caption{\label{fig:burgers_densities_delta_pwl}
Posterior densities, taken from the RW-chain shown above with piecewise-linear \(\delta = 0.1 \to 0.001\), burn-in 250 and sampling interval 20.}
\end{figure}

\bibliographystyle{plain}
\bibliography{../papers/inverse_problems}
\end{document}
